{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSMARCO_Corpus.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNTnN14QfeKaN35m2ToUfSL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragmalingu/experiments/blob/master/00_Data/MSMARCO_Corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e794AuGsT-DB"
      },
      "source": [
        "# MS MARCO (Microsoft Machine Reading Comprehension)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpHegKHfrs4I"
      },
      "source": [
        "You can get the corpus from this [link](https://github.com/microsoft/MSMARCO-Document-Ranking).\n",
        "For detailed information about the format of the files, see the PragmaLingu [Data Sets](https://pragmalingu.de/docs/guides/data-comparison). You can learn about parsing in general by reading our [parsing guide](https://pragmalingu.de/docs/guides/how-to-parse). \n",
        "\n",
        "Since MSMarco has over 3 million documents to index, it is not possible to download and run the parsing in Google Colab without a timeout. To index MSMarco on your own Elasticsearch index, copy this code into a file, set the path for the downloaded MS MARCO file and run it on your own machine. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Un-oDrHnDui"
      },
      "source": [
        "## Setup an Elasticsearch Instance in Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQiAH-sinDum"
      },
      "source": [
        "Everthing to connect to Elasticsearch, for detailed explaination see [this Notebook.](https://)\n",
        "Download:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdccmnTUnDup"
      },
      "source": [
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "# download elasticsearch\n",
        "!wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.1-linux-x86_64.tar.gz -q\n",
        "!tar -xzf elasticsearch-7.9.1-linux-x86_64.tar.gz\n",
        "!chown -R daemon:daemon elasticsearch-7.9.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxgS1p4_-zun"
      },
      "source": [
        "Start a local server:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9HrpRBGsg9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6968269-06e2-4e25-a9b5-390287afa39e"
      },
      "source": [
        "# start server\n",
        "es_server = Popen(['elasticsearch-7.9.1/bin/elasticsearch'], \n",
        "                  stdout=PIPE, stderr=STDOUT,\n",
        "                  preexec_fn=lambda: os.setuid(1)  # as daemon\n",
        "                 )\n",
        "# client-side\n",
        "!pip install elasticsearch -q\n",
        "from elasticsearch import Elasticsearch\n",
        "from datetime import datetime\n",
        "es = Elasticsearch([\"localhost:9200/\"])\n",
        "#wait a bit\n",
        "import time\n",
        "time.sleep(30)\n",
        "es.ping()  # got True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█                               | 10kB 14.4MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 17.5MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |████                            | 40kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 81kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 92kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 102kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 112kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 122kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 133kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 143kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 153kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 163kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 174kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 184kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 194kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 204kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 215kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 225kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 235kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 245kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 256kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 266kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 276kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 286kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 296kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 307kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 317kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 327kB 4.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsub7IvKYVVW"
      },
      "source": [
        "## Parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlYYOPBf1mfB"
      },
      "source": [
        "#!usr/bin/python3\n",
        "\n",
        "# set paths to the dowloaded data as variables\n",
        "PATH_TO_MARCO_TXT = './msmarco-docs.tsv' # enter path to where your MS MARCO file is saved\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import json\n",
        "import csv\n",
        "import sys\n",
        "\n",
        "# get the text file\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "tsv_file = open(PATH_TO_MARCO_TXT)\n",
        "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
        "marco_txt_data = defaultdict(dict)\n",
        "for row in read_tsv:\n",
        "  marco_txt_data[row[0]]['link'] = row[1]\n",
        "  marco_txt_data[row[0]]['title'] = row[2]\n",
        "  marco_txt_data[row[0]]['text'] = row[3]\n",
        "\n",
        "tsv_file.close()\n",
        "\n",
        "#create index, see https://elasticsearch-py.readthedocs.io/en/master/api.html#e$\n",
        "marco_index = \"pragmalingu-marco-corpus\"\n",
        "es.indices.create(marco_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdfWeFYbYazV"
      },
      "source": [
        "## Indexing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwkMI-J3nMlN"
      },
      "source": [
        "#create index, see https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create\n",
        "marco_index = \"marco-corpus\"\n",
        "\n",
        "es.indices.create(marco_index)\n",
        "#index documents, see https://elasticsearch-py.readthedocs.io/en/master/#example-usage\n",
        "for ID, doc_data in marco_txt_data.items():\n",
        "  es.index(index=marco_index, id=ID, body=doc_data)\n",
        "#print new index list\n",
        "create_response = es.cat.indices()\n",
        "print(create_response)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}