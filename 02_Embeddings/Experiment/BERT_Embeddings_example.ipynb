{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Embeddings_example.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6fd899d4a4a4cbda70f9cae2867ba0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ed8b2feb3d44e64bae17e3e32ad1b22",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cc0eb6e6b41144f6abb97fa45d41532e",
              "IPY_MODEL_6914d70e569f4ea78b1bae5026002a23"
            ]
          }
        },
        "5ed8b2feb3d44e64bae17e3e32ad1b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc0eb6e6b41144f6abb97fa45d41532e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e346198531544676b6b0f4758ef58173",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_046180d1f88b49f0b23b7de3cab9371f"
          }
        },
        "6914d70e569f4ea78b1bae5026002a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_24ce5b6fd9b34c769373b31649c235a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/? [00:10&lt;00:00,  3.50s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1fd21b48bb0a451aaccd1deee66031d8"
          }
        },
        "e346198531544676b6b0f4758ef58173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "046180d1f88b49f0b23b7de3cab9371f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24ce5b6fd9b34c769373b31649c235a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1fd21b48bb0a451aaccd1deee66031d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragmalingu/experiments/blob/master/02_Embeddings/Experiment/BERT_Embeddings_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vez_uAAlpyWs"
      },
      "source": [
        "# Bi-Directional Encoder Representation from Transformer (BERT)\n",
        "\n",
        "BERT is an approach of using large pretrained neural networks with some exceptional solutions to get the vectors from texts, which we can use with some similarity metrics like cosine similarity to compare meaning of these texts.\n",
        "\n",
        "(By the way these networks are frequently used as a backbone or part of ensemble of models to solve some NLP tasks like Question Answering, Ranking, Named Entitity Recognition, etc.)\n",
        "\n",
        "[\"I'm brave enough to read the paper on BERT\"](https://arxiv.org/abs/1810.04805)\n",
        "\n",
        "\n",
        "### How do we plan to use it?\n",
        "\n",
        " - get embeddings(vector representations) from documents using BERT\n",
        " - index them using knn algorithm included in ElasticSearch\n",
        " - get embeddings from queries(there're relevance labels of pairs query-document) using BERT\n",
        " - use relevance labels and ranking API from ElasticSearch to calculate metrics and compare it with classical approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rWL3C3BLMAR"
      },
      "source": [
        "## Basic Demonstration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Un-oDrHnDui"
      },
      "source": [
        "### Setup an Elasticsearch Instance in Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQiAH-sinDum"
      },
      "source": [
        "Everthing to connect to Elasticsearch, for detailed explaination see [this Notebook.](https://)\n",
        "Download:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdccmnTUnDup"
      },
      "source": [
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "# download elasticsearch\n",
        "!wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.1-linux-x86_64.tar.gz -q\n",
        "!tar -xzf elasticsearch-7.9.1-linux-x86_64.tar.gz\n",
        "!chown -R daemon:daemon elasticsearch-7.9.1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxgS1p4_-zun"
      },
      "source": [
        "Start a local server:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9HrpRBGsg9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0f7871-a52b-447f-c36c-b74c1d15b7c3"
      },
      "source": [
        "# start server\n",
        "es_server = Popen(['elasticsearch-7.9.1/bin/elasticsearch'], \n",
        "                  stdout=PIPE, stderr=STDOUT,\n",
        "                  preexec_fn=lambda: os.setuid(1)  # as daemon\n",
        "                 )\n",
        "# client-side\n",
        "!pip install elasticsearch -q\n",
        "from elasticsearch import Elasticsearch\n",
        "from datetime import datetime\n",
        "es = Elasticsearch([\"localhost:9200/\"])\n",
        "#wait a bit\n",
        "import time\n",
        "time.sleep(30)\n",
        "es.ping()  # got True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█                               | 10kB 5.2MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 8.9MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 6.0MB/s eta 0:00:01\r\u001b[K     |████                            | 40kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 71kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 81kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 92kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 102kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 112kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 122kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 133kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 143kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 153kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 163kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 174kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 184kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 194kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 204kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 215kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 225kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 235kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 245kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 256kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 266kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 276kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 286kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 296kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 307kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 317kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 327kB 5.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW1d1vUw_Bjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1952fd-f60f-4fa5-fd76-be5d721b4bfe"
      },
      "source": [
        "#print new index list\n",
        "create_response = es.cat.indices()\n",
        "print(create_response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXr3XUJ8Lg22"
      },
      "source": [
        "### Download pretrained BERT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_8fy6OMLfxt"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEmE5bgzLqZG"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "# using gpu to boost inference if it's possible\n",
        "if torch.cuda.is_available():\n",
        "  model.to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYDukY0kMnuD"
      },
      "source": [
        "print('Max Sequence Length:', model.max_seq_length)\n",
        "\n",
        "#Change the length to max possible length (based on gpu memory)\n",
        "model.max_seq_length = 364\n",
        "\n",
        "print('Max Sequence Length:', model.max_seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NaRtlXTLquq"
      },
      "source": [
        "sentences = ['This framework generates embeddings for each input sentence',\n",
        "    'Sentences are passed as a list of string.', \n",
        "    'The quick brown fox jumps over the lazy dog.']\n",
        "sentence_embeddings = model.encode(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox97uYV9LrHw"
      },
      "source": [
        "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
        "    print('Sentence:', sentence)\n",
        "    print('Embedding:', list(embedding[:5]) + ['...'])\n",
        "    print('Embedding\\'s length:', len(embedding))\n",
        "    print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73o0IvM0p0YW"
      },
      "source": [
        "### Indexing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK_Vw4dENIfX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3a24f71a-fe79-43f3-84da-4b6df66293b8"
      },
      "source": [
        "settings = {\n",
        "  \"settings\": {\n",
        "    \"index\": {\n",
        "      \"knn\": True,\n",
        "      \"knn.space_type\": \"cosinesimil\"\n",
        "    }\n",
        "  },\n",
        "  \"mappings\": {\n",
        "    \"properties\": {\n",
        "      \"bert_vector\": {\n",
        "        \"type\": \"knn_vector\",\n",
        "        \"dimension\": 768\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "#create index, see https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create\n",
        "toy_index = \"bert-toy_index\"\n",
        "es.indices.delete(index=toy_index, ignore=[400, 404])\n",
        "es.indices.create(toy_index, body=settings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acknowledged': True, 'index': 'bert-toy_index', 'shards_acknowledged': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9N6DKfjNI6M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "e6fd899d4a4a4cbda70f9cae2867ba0d",
            "5ed8b2feb3d44e64bae17e3e32ad1b22",
            "cc0eb6e6b41144f6abb97fa45d41532e",
            "6914d70e569f4ea78b1bae5026002a23",
            "e346198531544676b6b0f4758ef58173",
            "046180d1f88b49f0b23b7de3cab9371f",
            "24ce5b6fd9b34c769373b31649c235a2",
            "1fd21b48bb0a451aaccd1deee66031d8"
          ]
        },
        "outputId": "755f7694-41f7-4801-f883-b77048e96711"
      },
      "source": [
        "from tqdm import tqdm_notebook\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for i, sentence in tqdm_notebook(enumerate(sentences)):\n",
        "  with torch.no_grad():\n",
        "    if torch.cuda.is_available():\n",
        "      torch.cuda.ipc_collect()\n",
        "      torch.cuda.empty_cache()\n",
        "    es.index(\n",
        "      index=toy_index, \n",
        "      id=i, \n",
        "      body={\n",
        "          'bert_vector': model.encode(sentence),\n",
        "          'text': sentence\n",
        "          }\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6fd899d4a4a4cbda70f9cae2867ba0d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnZ63B7fpyKm"
      },
      "source": [
        "### Searching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIPjcEezP1Kb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "f1c38919-409b-4f13-dac0-590b0cbe6795"
      },
      "source": [
        "test_str = \"Where is the fox?\"\n",
        "\n",
        "#test query knn-search\n",
        "res = es.search(\n",
        "    index=\"bert-toy_index\", \n",
        "    body={\n",
        "        \"query\": {\n",
        "            \"knn\": {\n",
        "                \"bert_vector\": {\n",
        "                    \"vector\": list(model.encode(test_str).astype(float)),\n",
        "                    \"k\": 3\n",
        "                    }}}})\n",
        "\n",
        "print(\"Got %d Hits:\\n\\n\" % res['hits']['total']['value'])\n",
        "for hit in res['hits']['hits']:\n",
        "  print(f\"Cosine similarity score: {hit['_score']}  \\nid: {hit['_id']}\\ntext: {hit['_source']['text']}\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Got 3 Hits:\n",
            "\n",
            "\n",
            "Cosine similarity score: 0.6346718  \n",
            "id: 2\n",
            "text: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "\n",
            "Cosine similarity score: 0.5445194  \n",
            "id: 0\n",
            "text: This framework generates embeddings for each input sentence\n",
            "\n",
            "\n",
            "Cosine similarity score: 0.5397003  \n",
            "id: 1\n",
            "text: Sentences are passed as a list of string.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM_4F8AfhCh2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bcadd33-61ba-4473-b0ff-93d563a5d887"
      },
      "source": [
        "# Deleting index \n",
        "es.indices.delete(index=toy_index, ignore=[400, 404])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acknowledged': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}