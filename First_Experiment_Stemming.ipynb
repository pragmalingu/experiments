{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First Experiment: Stemming.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "57olkUd6WQ3C",
        "Gm1Aej_-T9e0"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragmalingu/experiments/blob/master/First_Experiment_Stemming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n93d8RqwhKXs",
        "colab_type": "text"
      },
      "source": [
        "# First Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tApgxGG-lbTG",
        "colab_type": "text"
      },
      "source": [
        "For our first experiment we connect the Notebook to an Elasticsearch instance and compare a standard Elasticsearch operator with two build-in stemming methods: 'Stemmer Token Filter' and 'Hunspell Token Filter'. \n",
        "(To read details about this experiment visit our [website](https://pragmalingu.de/docs/experiments/experiment1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Un-oDrHnDui"
      },
      "source": [
        "## Setup an Elasticsearch Instance in Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wQiAH-sinDum"
      },
      "source": [
        "Everthing to connect to Elasticsearch, for detailed explaination see [this Notebook.](https://)\n",
        "Download:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XdccmnTUnDup",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "# download elasticsearch\n",
        "!wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.1-linux-x86_64.tar.gz -q\n",
        "!tar -xzf elasticsearch-7.9.1-linux-x86_64.tar.gz\n",
        "!chown -R daemon:daemon elasticsearch-7.9.1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxgS1p4_-zun",
        "colab_type": "text"
      },
      "source": [
        "Start a local server:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9HrpRBGsg9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9ac6791c-42c9-4025-a235-5114ce62f851"
      },
      "source": [
        "# start server\n",
        "es_server = Popen(['elasticsearch-7.9.1/bin/elasticsearch'], \n",
        "                  stdout=PIPE, stderr=STDOUT,\n",
        "                  preexec_fn=lambda: os.setuid(1)  # as daemon\n",
        "                 )\n",
        "# client-side\n",
        "!pip install elasticsearch -q\n",
        "from elasticsearch import Elasticsearch\n",
        "from datetime import datetime\n",
        "es = Elasticsearch([\"localhost:9200/\"])\n",
        "#wait a bit\n",
        "import time\n",
        "time.sleep(30)\n",
        "es.ping()  # got True"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▌                              | 10kB 18.5MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 6.5MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 51kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 71kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 92kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 102kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 112kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 122kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 133kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 143kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 153kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 163kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 174kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 184kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 194kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 204kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 215kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 5.9MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0j2BkMTXdiD",
        "colab_type": "text"
      },
      "source": [
        "## Initialize Stemmers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9EMclEPLvMS",
        "colab_type": "text"
      },
      "source": [
        "### Algorithmic Stemmer\n",
        "\n",
        "Algorithmic stemmers apply a series of rules to each word to reduce it to its root form.\n",
        "\n",
        "In this way, they present a few advantages:\n",
        "1. They require little setup and usually work well out of the box;\n",
        "2. They use little memory;\n",
        "3. They are typically faster than dictionary stemmers.\n",
        "\n",
        "(For more information see the [Elasticsearch documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/stemming.html#algorithmic-stemmers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz4HOfBQzEpL",
        "colab_type": "text"
      },
      "source": [
        "**Analyzer**\n",
        "\n",
        "An analyzer contains three lower-level building blocks: character filters, a tokenizer, and token filters.\n",
        "To apply stemming we first need to configure a custom analyzer that makes use of the stemmer filter. \n",
        "\n",
        "(Stemmer filter reference guide at [Elasticsearch documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-stemmer-tokenfilter.html#analysis-stemmer-tokenfilter))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1rgB2Wm3YkrX",
        "colab": {}
      },
      "source": [
        "#the order of filter and analyzer is arbitrary\n",
        "stemming_analyzer = {\n",
        "    \"filter\" : {\n",
        "        \"eng_stemmer\" : {\n",
        "        \"type\" : \"stemmer\",\n",
        "        \"name\" : \"english\"\n",
        "        }\n",
        "    },\n",
        "    \"analyzer\" : {\n",
        "        \"default\" : {\n",
        "            \"tokenizer\" : \"standard\",\n",
        "            \"filter\" : [\"lowercase\", \"eng_stemmer\"]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "#create the correct settings \n",
        "stemmer_settings = {\n",
        "    \"settings\": {\n",
        "        \"number_of_shards\": 1,\n",
        "        \"number_of_replicas\": 0,\n",
        "        \"analysis\": stemming_analyzer\n",
        "    }\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y1DRyRSxZZE7"
      },
      "source": [
        "### Dictionary Stemmer\n",
        "\n",
        "Dictionary stemmers look up words in a provided dictionary, replacing unstemmed word variants with stemmed words from the dictionary.\n",
        "\n",
        "In theory, these are well suited for:\n",
        "1. Stemming irregular words;\n",
        "2. Discerning between words that are spelled similarly but not related conceptually.\n",
        "\n",
        "They also admit a few drawbacks:\n",
        "1. Highly dependent on dictionary quality;\n",
        "2. Size and performance, as a result of having to load all words, prefixes and suffixes from the dictionary.\n",
        "\n",
        "(For more information see the [Elasticsearch documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/stemming.html#dictionary-stemmers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HxkrKlValTqM"
      },
      "source": [
        "**Analyzer**\n",
        "\n",
        "An analyzer contains three lower-level building blocks: character filters, a tokenizer, and token filters.\n",
        "To apply dictionary stemming, we first need to configure a custom analyzer that makes use of the stemmer filter. \n",
        "\n",
        "(Hunspell filter reference guide at [Elasticsearch documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-hunspell-tokenfilter.html#analysis-hunspell-tokenfilter))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-S1Zl9JLZZFP",
        "colab": {}
      },
      "source": [
        "#the order of filter and analyzer is arbitrary\n",
        "dictionary_analyzer = {\n",
        "    \"filter\" : {\n",
        "        \"dictionary_stemmer\" : {\n",
        "          \"type\" : \"hunspell\",\n",
        "          \"locale\" : \"en_US\",\n",
        "          \"dedup\" : True  #duplicate tokens are removed from the filter’s output\n",
        "        }\n",
        "    },\n",
        "    \"analyzer\" : {\n",
        "        \"default\" : {\n",
        "            \"tokenizer\" : \"standard\",\n",
        "            \"filter\" : [\"lowercase\", \"dictionary_stemmer\"]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "#create the correct settings \n",
        "hunspell_settings = {\n",
        "    \"settings\": {\n",
        "        \"number_of_shards\": 1,\n",
        "        \"number_of_replicas\": 0,\n",
        "        \"analysis\": dictionary_analyzer\n",
        "    }\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM88eyhNCWg4",
        "colab_type": "text"
      },
      "source": [
        "**Dictionary**\n",
        "\n",
        "To use the Hunspell Token Stemmer for English US you have to download the Hunspell dictionary for that language and make it accessable for your Elasticsearch instance at 'elsaticsearch-7.9.1/ect/elasticsearch/hunspell/en_US':\n",
        "(For more information visit the [Elasticsearch Website](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-hunspell-tokenfilter.html#analysis-hunspell-tokenfilter-dictionary-config))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxEPsWiACWAY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "6634d01a-6ec5-4ce2-977a-dd2080adb91a"
      },
      "source": [
        "!wget https://cgit.freedesktop.org/libreoffice/dictionaries/tree/en/en_US.aff -P /content/elasticsearch-7.9.1/config/hunspell/en_US\n",
        "!wget https://cgit.freedesktop.org/libreoffice/dictionaries/tree/en/en_US.dic -P /content/elasticsearch-7.9.1/config/hunspell/en_US"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-16 06:58:10--  https://cgit.freedesktop.org/libreoffice/dictionaries/tree/en/en_US.aff\n",
            "Resolving cgit.freedesktop.org (cgit.freedesktop.org)... 131.252.210.161\n",
            "Connecting to cgit.freedesktop.org (cgit.freedesktop.org)|131.252.210.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘/content/elasticsearch-7.9.1/config/hunspell/en_US/en_US.aff’\n",
            "\n",
            "en_US.aff               [ <=>                ]  23.45K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-09-16 06:58:11 (162 KB/s) - ‘/content/elasticsearch-7.9.1/config/hunspell/en_US/en_US.aff’ saved [24012]\n",
            "\n",
            "--2020-09-16 06:58:11--  https://cgit.freedesktop.org/libreoffice/dictionaries/tree/en/en_US.dic\n",
            "Resolving cgit.freedesktop.org (cgit.freedesktop.org)... 131.252.210.161\n",
            "Connecting to cgit.freedesktop.org (cgit.freedesktop.org)|131.252.210.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘/content/elasticsearch-7.9.1/config/hunspell/en_US/en_US.dic’\n",
            "\n",
            "en_US.dic               [     <=>            ]   2.40M  2.02MB/s    in 1.2s    \n",
            "\n",
            "2020-09-16 06:58:13 (2.02 MB/s) - ‘/content/elasticsearch-7.9.1/config/hunspell/en_US/en_US.dic’ saved [2513218]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag13xWCxqsgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo \"#indices.analysis.hunspell.dictionary.location : /content/elasticsearch-7.9.1\" >> elasticsearch-7.9.1/config/elasticsearch.yml"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6wAsx4Hr_Qz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9054d7f8-5e54-4a14-9939-13a7b4b70bc1"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ADI.ALL  ADI.QRY  adi.tar.gz\t       elasticsearch-7.9.1-linux-x86_64.tar.gz\n",
            "ADI.BLN  ADI.REL  elasticsearch-7.9.1  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TxkfxWauoWbG"
      },
      "source": [
        "## Parse Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrwEamOKAJKI",
        "colab_type": "text"
      },
      "source": [
        "Get different corpora, format them and feed them to elasticsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zjiZiQqBB1ax"
      },
      "source": [
        "### ADI Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WIwc13MToWb3"
      },
      "source": [
        "**Parsing**\n",
        "\n",
        "You can get the corpus from [this link](http://ir.dcs.gla.ac.uk/resources/test_collections/adi/).  <br>\n",
        "For detailed information about the parsing of this corpus look at [ this Notebook](https://colab.research.google.com/github/pragmalingu/private_experiments/blob/adi_corpus/ADICorpus.ipynb) or for parsing in generel read [this guide](https://)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R-hYomDBB1ay",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "38ccff64-3d30-4ae8-efaa-e655dfff5048"
      },
      "source": [
        "# download and unzip data\n",
        "!wget http://ir.dcs.gla.ac.uk/resources/test_collections/adi/adi.tar.gz\n",
        "!tar -xf adi.tar.gz\n",
        "\n",
        "# set paths to the dowloaded data as variables\n",
        "PATH_TO_ADI_TXT = '/content/ADI.ALL'\n",
        "\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import json\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "\n",
        "# get the text and query files\n",
        "\n",
        "ID_marker = re.compile('\\.I')\n",
        "\n",
        "def get_data(PATH_TO_FILE, marker):\n",
        "  \"\"\"\n",
        "  Reads file and spilts text into entries at the ID marker '.I'.\n",
        "  First entry is empty, so it's removed.\n",
        "  'marker' contains the regex at which we want to split\n",
        "  \"\"\"\n",
        "  with open (PATH_TO_FILE,'r') as f:\n",
        "    text = f.read().replace('\\n',\" \")\n",
        "    lines = re.split(marker,text)\n",
        "    lines.pop(0)\n",
        "  return lines\n",
        "\n",
        "adi_txt_list = get_data(PATH_TO_ADI_TXT, ID_marker)\n",
        "\n",
        "# process text file\n",
        "\n",
        "adi_title_start = re.compile('\\.T')\n",
        "adi_author_start = re.compile('\\.A')\n",
        "adi_text_start = re.compile('\\.W')\n",
        "\n",
        "adi_txt_data = defaultdict(dict)\n",
        "\n",
        "for line in adi_txt_list:\n",
        "  entries = re.split(adi_title_start,line,1)\n",
        "  id = entries[0].strip()\n",
        "  no_id = entries[1]\n",
        "  if len(re.split(adi_author_start, no_id,1)) > 1:\n",
        "    no_id_entries = re.split(adi_author_start, no_id,1)\n",
        "    adi_txt_data[id]['title'] = no_id_entries[0]\n",
        "    no_title = no_id_entries[1]\n",
        "    no_title_entries = re.split(adi_text_start, no_title)\n",
        "    adi_txt_data[id]['author'] = no_title_entries[0]\n",
        "    adi_txt_data[id]['text'] = no_title_entries[1]\n",
        "  else:\n",
        "    no_id_entries = re.split(adi_text_start, no_id)\n",
        "    adi_txt_data[id]['title'] = no_id_entries[0]\n",
        "    adi_txt_data[id]['text'] = no_id_entries[1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-16 06:58:25--  http://ir.dcs.gla.ac.uk/resources/test_collections/adi/adi.tar.gz\n",
            "Resolving ir.dcs.gla.ac.uk (ir.dcs.gla.ac.uk)... 130.209.240.253\n",
            "Connecting to ir.dcs.gla.ac.uk (ir.dcs.gla.ac.uk)|130.209.240.253|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17307 (17K) [application/gzip]\n",
            "Saving to: ‘adi.tar.gz’\n",
            "\n",
            "\radi.tar.gz            0%[                    ]       0  --.-KB/s               \radi.tar.gz          100%[===================>]  16.90K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-09-16 06:58:25 (797 KB/s) - ‘adi.tar.gz’ saved [17307/17307]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CFxeglUsbjHY"
      },
      "source": [
        "**Indexing**\n",
        "\n",
        "Create an index of the adi corpus for every test setting and index all the documents. This is only possible if it isn't created yet.\n",
        "\n",
        "(For more information see the [Elasticsearch documentation](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IraDfSc3t-jZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8772d90e-fedc-470c-efb7-665793e0e51e"
      },
      "source": [
        "es.indices.delete(adi_index)\n",
        "es.indices.delete(stemmer_adi_index)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acknowledged': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ISoDO5nfbjHa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "4a8f2360-ec20-4a2f-b977-cc06782d7763"
      },
      "source": [
        "#create index, see https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create\n",
        "adi_index = \"adi-corpus\"\n",
        "stemmer_adi_index = \"stemmer-adi-corpus\"\n",
        "hunspell_adi_index = \"hunspell-adi-corpus\"\n",
        "\n",
        "es.indices.create(adi_index)\n",
        "es.indices.create(stemmer_adi_index, body=stemmer_settings)\n",
        "es.indices.create(hunspell_adi_index, body=hunspell_settings)\n",
        "#index document, see https://elasticsearch-py.readthedocs.io/en/master/#example-usage\n",
        "for ID, doc_data in adi_txt_data.items():\n",
        "  es.index(index=adi_index, id=ID, body=doc_data)\n",
        "  es.index(index=stemmer_adi_index, id=ID, body=doc_data)\n",
        "  es.index(index=hunspell_adi_index, id=ID, body=doc_data)\n",
        "\n",
        "create_response = es.cat.indices()\n",
        "print(create_response)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TransportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTransportError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6e03e54fcddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madi_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmer_adi_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstemmer_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhunspell_adi_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhunspell_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#index document, see https://elasticsearch-py.readthedocs.io/en/master/#example-usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madi_txt_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/elasticsearch/client/utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/elasticsearch/client/indices.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, index, body, params, headers)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         return self.transport.perform_request(\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;34m\"PUT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_make_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         )\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    390\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    363\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                     \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 )\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/elasticsearch/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             )\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         self.log_request_success(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/elasticsearch/connection/base.py\u001b[0m in \u001b[0;36m_raise_error\u001b[0;34m(self, status_code, raw_data)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         raise HTTP_EXCEPTIONS.get(status_code, TransportError)(\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         )\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTransportError\u001b[0m: TransportError(500, 'illegal_state_exception', 'failed to load hunspell dictionary for locale: en_US')"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PKtJrp2toWcX"
      },
      "source": [
        "### CACM Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wyZpwjmboWcY"
      },
      "source": [
        "**Parsing**\n",
        "\n",
        "You can get the corpus from [this link](http://ir.dcs.gla.ac.uk/resources/test_collections/cacm/).  <br>\n",
        "For detailed information about the format of the files, see the PragmaLingu [ Benchmarks](https://pragmalingu.de/docs/benchmarks/overview)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PJMfaWc4oWca",
        "colab": {}
      },
      "source": [
        "# download and unzip data\n",
        "!wget http://ir.dcs.gla.ac.uk/resources/test_collections/cacm/cacm.tar.gz\n",
        "!tar -xf cacm.tar.gz\n",
        "\n",
        "# set paths to the dowloaded data as variablesDownload and unzip data.\n",
        "\n",
        "PATH_TO_CACM_TXT = '/content/cacm.all'\n",
        "\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import json\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "\n",
        "# get the text and query files\n",
        "\n",
        "ID_marker = re.compile('^\\.I',re.MULTILINE)\n",
        "\n",
        "def get_data(PATH_TO_FILE, marker):\n",
        "  \"\"\"\n",
        "  Reads file and spilts text into entries at the ID marker '.I'.\n",
        "  First entry is empty, so it's removed.\n",
        "  'marker' contains the regex at which we want to split\n",
        "  \"\"\"\n",
        "  with open (PATH_TO_FILE,'r') as f:\n",
        "    text = f.read()\n",
        "    lines = re.split(marker,text)\n",
        "    lines.pop(0)\n",
        "  return lines\n",
        "\n",
        "cacm_txt_list = get_data(PATH_TO_CACM_TXT, ID_marker)\n",
        "\n",
        "# process text file\n",
        "\n",
        "cacm_chunk_title = re.compile('\\.[T]\\n')\n",
        "cacm_chunk_txt = re.compile('\\n\\.W\\n') # not enough\n",
        "cacm_chunk_txt_pub = re.compile('\\.[W,B]')\n",
        "cacm_chunk_publication = re.compile('\\.[B]\\n')\n",
        "cacm_chunk_author = re.compile('^\\.[A]\\n', re.MULTILINE)\n",
        "cacm_chunk_author_add_cross = re.compile('^\\.[A,N,X]\\n',re.MULTILINE) # not enough\n",
        "cacm_chunk_add_cross = re.compile('\\.[B,N,X]\\n')\n",
        "\n",
        "\n",
        "cacm_txt_data = defaultdict(dict)\n",
        "\n",
        "for line in cacm_txt_list:\n",
        "  entries= re.split(cacm_chunk_title,line)\n",
        "  id = entries[0].strip() #save id\n",
        "  no_id = entries[1]\n",
        "\n",
        "  if len(re.split(cacm_chunk_txt, no_id)) == 2: # is there text\n",
        "    no_id_entries = re.split(cacm_chunk_txt_pub, no_id,1)\n",
        "    cacm_txt_data[id]['title'] = no_id_entries[0].strip() # save title\n",
        "    cacm_txt_data[id]['text'] = no_id_entries[1].strip() # save text\n",
        "    no_title_txt = no_id_entries[1]\n",
        "\n",
        "    if len(re.split(cacm_chunk_author, no_title_txt)) == 2: # is there a auhtor\n",
        "      no_title_entries = re.split(cacm_chunk_author_add_cross, no_title_txt)\n",
        "      cacm_txt_data[id]['publication_date'] = no_title_entries[0].strip() # save publication date\n",
        "      cacm_txt_data[id]['author'] = no_title_entries[1].strip() # save athor\n",
        "      cacm_txt_data[id]['add_date'] = no_title_entries[2].strip() # save add date\n",
        "      cacm_txt_data[id]['cross-references'] = no_title_entries[3].strip() # save cross-references\n",
        "\n",
        "    else:\n",
        "      no_title_entries = re.split(cacm_chunk_publication, no_title_txt)\n",
        "      cacm_txt_data[id]['publication_date'] = no_title_entries[0].strip() # save publication date\n",
        "      cacm_txt_data[id]['add_date'] = no_title_entries[1].strip() # save add date\n",
        "      cacm_txt_data[id]['cross-references'] = no_title_entries[1].strip() # save cross-references\n",
        "\n",
        "  else:\n",
        "    no_id_entries = re.split(cacm_chunk_publication, no_id,1)\n",
        "    cacm_txt_data[id]['title'] = no_id_entries[0].strip() # save title\n",
        "    no_title = no_id_entries[1]\n",
        "\n",
        "    if len(re.split(cacm_chunk_author, no_title,1)) == 2: # is there a auhtor\n",
        "      no_title_entries = re.split(cacm_chunk_author_add_cross, no_title)\n",
        "      cacm_txt_data[id]['publication_date'] = no_title_entries[0].strip() # save publication date\n",
        "      cacm_txt_data[id]['author'] = no_title_entries[1].strip() # save athor\n",
        "      cacm_txt_data[id]['add_date'] = no_title_entries[2].strip() # save add date\n",
        "      cacm_txt_data[id]['cross-references'] = no_title_entries[3].strip() # save cross-references\n",
        "\n",
        "    else:\n",
        "      no_title_entries = re.split(cacm_chunk_add_cross, no_title)\n",
        "      cacm_txt_data[id]['publication_date'] = no_title_entries[0].strip() # save publication date\n",
        "      cacm_txt_data[id]['add_date'] = no_title_entries[1].strip() # save add date\n",
        "      cacm_txt_data[id]['cross-references'] = no_title_entries[2].strip() # save cross-references"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XtidLeKFb3OE"
      },
      "source": [
        "**Indexing**\n",
        "\n",
        "Create an index of the CACM corpus for every test setting and index all the documents. This is only possible if it isn't created yet.\n",
        "\n",
        "(For more information see the [Elasticsearch documentation](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SG8pu2Knb3OH",
        "colab": {}
      },
      "source": [
        "#create index, see https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create\n",
        "cacm_index = \"cacm-corpus\"\n",
        "stemmer_cacm_index = \"stemmer-cacm-corpus\"\n",
        "hunspell_cacm_index = \"hunspell-cacm-corpus\"\n",
        "\n",
        "es.indices.create(cacm_index)\n",
        "es.indices.create(stemmer_cacm_index, body=stemmer_settings)\n",
        "es.indices.create(hunspell_cacm_index, body=hunspell_settings)\n",
        "#index document, see https://elasticsearch-py.readthedocs.io/en/master/#example-usage\n",
        "for ID, doc_data in cacm_txt_data.items():\n",
        "  es.index(index=cacm_index, id=ID, body=doc_data)\n",
        "  es.index(index=stemmer_cacm_index, id=ID, body=doc_data)\n",
        "  es.index(index=hunspell_cacm_index, id=ID, body=doc_data)\n",
        "\n",
        "create_response = es.cat.indices()\n",
        "print(create_response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TV7rks6ToWcL"
      },
      "source": [
        "### CISI Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "86yPro8JoWcM"
      },
      "source": [
        "**Parsing** \n",
        "\n",
        "can get the corpus from [this link](http://ir.dcs.gla.ac.uk/resources/test_collections/cisi/).  <br>\n",
        "For detailed information about the parsing of this corpus look at [ this Notebook](https://colab.research.google.com/github/pragmalingu/private_experiments/blob/cisi_corpus/CISICorpus.ipynb) or for parsing in generel read [this guide](https://)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zpl4dnl_oWcM",
        "colab": {}
      },
      "source": [
        "\n",
        "# download and unzip data\n",
        "!wget http://ir.dcs.gla.ac.uk/resources/test_collections/cisi/cisi.tar.gz\n",
        "!tar -xf cisi.tar.gz\n",
        "\n",
        "# set paths to the dowloaded data as variablesDownload and unzip data.\n",
        "PATH_TO_CISI_TXT = '/content/CISI.ALL'\n",
        "\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import json\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "\n",
        "# get the text file\n",
        "\n",
        "ID_marker = re.compile('^\\.I',re.MULTILINE)\n",
        "\n",
        "def get_data(PATH_TO_FILE, marker):\n",
        "  \"\"\"\n",
        "  Reads file and spilts text into entries at the ID marker '.I'.\n",
        "  First entry is empty, so it's removed.\n",
        "  'marker' contains the regex at which we want to split\n",
        "  \"\"\"\n",
        "  with open (PATH_TO_FILE,'r') as f:\n",
        "    text = f.read()\n",
        "    lines = re.split(marker,text)\n",
        "    lines.pop(0)\n",
        "  return lines\n",
        "\n",
        "cisi_txt_list = get_data(PATH_TO_CISI_TXT, ID_marker)\n",
        "\n",
        "# process text file\n",
        "\n",
        "cisi_title_start = re.compile('[\\n]\\.T')\n",
        "cisi_author_start = re.compile('[\\n]\\.A')\n",
        "cisi_date_start = re.compile('[\\n]\\.B')\n",
        "cisi_text_start = re.compile('[\\n]\\.W')\n",
        "cisi_cross_start = re.compile('[\\n]\\.X')\n",
        "\n",
        "cisi_txt_data = defaultdict(dict)\n",
        "\n",
        "for line in cisi_txt_list:\n",
        "  entries = re.split(cisi_title_start,line,1)\n",
        "  id = entries[0].strip()#save the id\n",
        "  no_id = entries[1] \n",
        "  \n",
        "  if len(re.split(cisi_author_start, no_id)) >= 2: # is there just one author?\n",
        "    no_id_entries = re.split(cisi_author_start, no_id,1)\n",
        "    cisi_txt_data[id]['title'] = no_id_entries[0].strip() # save title\n",
        "    no_title = no_id_entries[1]\n",
        "\n",
        "    if len(re.split(cisi_date_start, no_title)) > 1: # is there a publication date?\n",
        "      no_title_entries = re.split(cisi_date_start, no_title)\n",
        "      cisi_txt_data[id]['author'] = no_title_entries[0].strip() # save athour\n",
        "      no_author = no_title_entries[1]\n",
        "      no_author_entries = re.split(cisi_text_start, no_author)\n",
        "      cisi_txt_data[id]['publication_date'] = no_author_entries[0].strip() # save publication date\n",
        "      no_author_date = no_author_entries[1]\n",
        "    else:\n",
        "      no_title_entries = re.split(cisi_text_start, no_title)\n",
        "      cisi_txt_data[id]['author'] = no_title_entries[0].strip() # save athour\n",
        "      no_author_date = no_title_entries[1]\n",
        "\n",
        "  else:\n",
        "    no_id_entries = re.split(cisi_author_start, no_id)\n",
        "    cisi_txt_data[id]['title'] = no_id_entries[0].strip() # save title\n",
        "    cisi_txt_data[id]['author'] = no_id_entries[1].strip() # save first author\n",
        "    no_title_entries = re.split(cisi_text_start, no_title)\n",
        "    cisi_txt_data[id]['author'] += ','+no_title_entries[0].strip() # save second athour\n",
        "    no_author_date = no_title_entries[1]\n",
        "\n",
        "  last_entries = re.split(cisi_cross_start, no_author_date)\n",
        "  cisi_txt_data[id]['text'] = last_entries[0].strip() # save text\n",
        "  cisi_txt_data[id]['cross-refrences'] = last_entries[1].strip() # save cross refrences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KliMTl3JcXOA"
      },
      "source": [
        "**Indexing**\n",
        "\n",
        "Create an index of the CISI corpus for every test setting and index all the documents. This is only possible if it isn't created yet.\n",
        "\n",
        "(For more information see the [Elasticsearch documentation](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SACv5mWtcXOC",
        "colab": {}
      },
      "source": [
        "#create index, see https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create\n",
        "cisi_index = \"cisi-corpus\"\n",
        "stemmer_cisi_index = \"stemmer-cisi-corpus\"\n",
        "hunspell_cisi_index = \"hunspell-cisi-corpus\"\n",
        "\n",
        "es.indices.create(cisi_index)\n",
        "es.indices.create(stemmer_cisi_index, body=stemmer_settings)\n",
        "es.indices.create(hunspell_cisi_index, body=hunspell_settings)\n",
        "#index document, see https://elasticsearch-py.readthedocs.io/en/master/#example-usage\n",
        "for ID, doc_data in cisi_txt_data.items():\n",
        "  es.index(index=cisi_index, id=ID, body=doc_data)\n",
        "  es.index(index=stemmer_cisi_index, id=ID, body=doc_data)\n",
        "  es.index(index=hunspell_cisi_index, id=ID, body=doc_data)\n",
        "\n",
        "create_response = es.cat.indices()\n",
        "print(create_response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S1FZPluBoWbL"
      },
      "source": [
        "### Cranfield Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d8BsqgrXoWbO"
      },
      "source": [
        "**Parsing**\n",
        "\n",
        "You can get the corpus from [this link](http://ir.dcs.gla.ac.uk/resources/test_collections/cran/).  <br>\n",
        "For detailed information about the parsing of this corpus look at [ this Notebook](https://colab.research.google.com/github/pragmalingu/private_experiments/blob/cranfield_corpus/CranfieldCorpus.ipynb) or for parsing in generel read [this guide](https://)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rm9vj7l7oWbQ",
        "colab": {}
      },
      "source": [
        "# download and unzip data\n",
        "!wget http://ir.dcs.gla.ac.uk/resources/test_collections/cran/cran.tar.gz\n",
        "!tar -xf cran.tar.gz\n",
        "\n",
        "# set paths to the dowloaded data as variables\n",
        "PATH_TO_CRAN_TXT = '/content/cran.all.1400'\n",
        "\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import json\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "\n",
        "# get the text entries from the text and query files\n",
        "\n",
        "ID_marker = re.compile('\\.I')\n",
        "\n",
        "def get_data(PATH_TO_FILE, marker):\n",
        "  \"\"\"\n",
        "  Reads file and spilts text into entries at the ID marker '.I'.\n",
        "  First entry is empty, so it's removed.\n",
        "  'marker' contains the regex at which we want to split\n",
        "  \"\"\"\n",
        "  with open (PATH_TO_FILE,'r') as f:\n",
        "    text = f.read().replace('\\n',\" \")\n",
        "    lines = re.split(marker,text)\n",
        "    lines.pop(0)\n",
        "  return lines\n",
        "\n",
        "cran_txt_list = get_data(PATH_TO_CRAN_TXT, ID_marker)\n",
        "\n",
        "# process text file\n",
        "\n",
        "cran_chunk_start = re.compile('\\.[A,B,T,W]')\n",
        "cran_txt_data = defaultdict(dict)\n",
        "\n",
        "for line in cran_txt_list:\n",
        "  entries= re.split(cran_chunk_start,line)\n",
        "  id = entries[0].strip()\n",
        "  title = entries[1]\n",
        "  author = entries[2]\n",
        "  publication_date = entries[3]\n",
        "  text = entries[4]\n",
        "  cran_txt_data[id]['title'] = title\n",
        "  cran_txt_data[id]['author'] = author\n",
        "  cran_txt_data[id]['publication_date'] = publication_date\n",
        "  cran_txt_data[id]['text'] = text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9dex8ehBEXAz"
      },
      "source": [
        "**Indexing**\n",
        "\n",
        "Create an index of the Cranfield corpus for every test setting and index all the documents. This is only possible if it isn't created yet.\n",
        "\n",
        "(For more information see the [Elasticsearch documentation](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rs-sHqHZEXA1",
        "colab": {}
      },
      "source": [
        "#create index, see https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create\n",
        "cranfield_index = \"cranfield-corpus\"\n",
        "stemmer_cranfield_index = \"stemmer-cranfield-corpus\"\n",
        "hunspell_cranfield_index = \"hunspell-cranfield-corpus\"\n",
        "\n",
        "es.indices.create(cranfield_index)\n",
        "es.indices.create(stemmer_cranfield_index, body=stemmer_settings)\n",
        "es.indices.create(hunspell_cranfield_index, body=hunspell_settings)\n",
        "#index document, see https://elasticsearch-py.readthedocs.io/en/master/#example-usage\n",
        "for ID, doc_data in cranfield_txt_data.items():\n",
        "  es.index(index=cranfield_index, id=ID, body=doc_data)\n",
        "  es.index(index=stemmer_cranfield_index, id=ID, body=doc_data)\n",
        "  es.index(index=hunspell_cranfield_index, id=ID, body=doc_data)\n",
        "\n",
        "create_response = es.cat.indices()\n",
        "print(create_response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XMSAoYTXoWcj"
      },
      "source": [
        "### LISA Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ot7zglmMoWcl"
      },
      "source": [
        "**Parsing**\n",
        "\n",
        "You can get the corpus from [this link](http://ir.dcs.gla.ac.uk/resources/test_collections/lisa/).  <br>\n",
        "For detailed information about the format of the files, see the PragmaLingu [ Benchmarks](https://pragmalingu.de/docs/benchmarks/overview)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F5zQOC6xoWcm",
        "colab": {}
      },
      "source": [
        "# download and unzip data\n",
        "!wget http://ir.dcs.gla.ac.uk/resources/test_collections/lisa/lisa.tar.gz\n",
        "!tar -xf lisa.tar.gz\n",
        "\n",
        "# set paths to the dowloaded data as variables\n",
        "\n",
        "PATH_TO_LISA_TXT = '/content/'\n",
        "\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import json\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# get the text files\n",
        "\n",
        "file_regex = re.compile('LISA[0-5]')\n",
        "lisa_files = [i for i in os.listdir(PATH_TO_LISA_TXT) if os.path.isfile(os.path.join(PATH_TO_LISA_TXT,i)) and re.match(file_regex,i)]\n",
        "\n",
        "txt_entry_marker = re.compile('\\*{44}',re.MULTILINE)\n",
        "\n",
        "def get_data(PATH_TO_FILES, marker):\n",
        "  \"\"\"\n",
        "  Reads multiple files and spilts text into entries at the entry marker.\n",
        "  The 'marker' contains the regex at which we want to split\n",
        "  Pops last element since it's empty.\n",
        "  \"\"\"\n",
        "  with open (PATH_TO_FILES,'r') as f:\n",
        "    text = f.read().replace('     ','')\n",
        "    lines = re.split(marker,text)\n",
        "    lines.pop()\n",
        "  return lines\n",
        "\n",
        "lisa_txt_list = []\n",
        "for name in lisa_files: \n",
        "  lisa_txt_list.extend(get_data(PATH_TO_LISA_TXT+name, txt_entry_marker))\n",
        "\n",
        "# process text file\n",
        "\n",
        "doc_strip = re.compile('\\n?Document {1,2}')\n",
        "\n",
        "lisa_txt_list_stripped = []\n",
        "lisa_txt_data = defaultdict(dict)\n",
        "\n",
        "for el in lisa_txt_list:\n",
        "  lisa_txt_list_stripped.append(re.sub(doc_strip,'', el))\n",
        "\n",
        "for entry in lisa_txt_list_stripped:\n",
        "  parts = entry.split('\\n')\n",
        "  empty_index = parts.index('')\n",
        "  ID = parts[0]\n",
        "  title = parts[1:empty_index]\n",
        "  text = parts[empty_index+1:]\n",
        "  lisa_txt_data[ID]['title'] = title\n",
        "  lisa_txt_data[ID]['text'] = text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O8nsJ67Nckia"
      },
      "source": [
        "**Indexing**\n",
        "\n",
        "Create an index of the LISA corpus for every test setting and index all the documents. This is only possible if it isn't created yet.\n",
        "\n",
        "(For more information see the [Elasticsearch documentation](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g369ZaZ2ckid",
        "colab": {}
      },
      "source": [
        "#create index, see https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create\n",
        "lisa_index = \"lisa-corpus\"\n",
        "stemmer_lisa_index = \"stemmer-lisa-corpus\"\n",
        "hunspell_lisa_index = \"hunspell-lisa-corpus\"\n",
        "\n",
        "es.indices.create(lisa_index)\n",
        "es.indices.create(stemmer_lisa_index, body=stemmer_settings)\n",
        "es.indices.create(hunspell_lisa_index, body=hunspell_settings)\n",
        "#index document, see https://elasticsearch-py.readthedocs.io/en/master/#example-usage\n",
        "for ID, doc_data in lisa_txt_data.items():\n",
        "  es.index(index=lisa_index, id=ID, body=doc_data)\n",
        "  es.index(index=stemmer_lisa_index, id=ID, body=doc_data)\n",
        "  es.index(index=hunspell_lisa_index, id=ID, body=doc_data)\n",
        "\n",
        "create_response = es.cat.indices()\n",
        "print(create_response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BbhrYkLXoWbk"
      },
      "source": [
        "### Medline Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cFc3bnl3oWbm"
      },
      "source": [
        "**Parsing**\n",
        "\n",
        "You can get the corpus from [this link](http://ir.dcs.gla.ac.uk/resources/test_collections/med/).  <br>\n",
        "For detailed information about the parsing of this corpus look at [ this Notebook](https://colab.research.google.com/github/pragmalingu/private_experiments/blob/medline_corpus/MedlineCorpus.ipynb) or for parsing in generel read [this guide](https://)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BEjl85pXoWbn",
        "colab": {}
      },
      "source": [
        "# download and unzip data\n",
        "!wget http://ir.dcs.gla.ac.uk/resources/test_collections/medl/med.tar.gz\n",
        "!tar -xf med.tar.gz\n",
        "\n",
        "# set paths to the dowloaded data as variables\n",
        "PATH_TO_MED_TXT = '/content/MED.ALL'\n",
        "\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import json\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "\n",
        "# get the text and query files\n",
        "\n",
        "ID_marker = re.compile('\\.I')\n",
        "\n",
        "def get_data(PATH_TO_FILE, marker):\n",
        "  \"\"\"\n",
        "  Reads file and spilts text into entries at the ID marker '.I'.\n",
        "  First entry is empty, so it's removed.\n",
        "  'marker' contains the regex at which we want to split\n",
        "  \"\"\"\n",
        "  with open (PATH_TO_FILE,'r') as f:\n",
        "    text = f.read().replace('\\n',\" \")\n",
        "    lines = re.split(marker,text)\n",
        "    lines.pop(0)\n",
        "  return lines\n",
        "\n",
        "med_txt_list = get_data(PATH_TO_MED_TXT, ID_marker)\n",
        "\n",
        "# process the text file\n",
        "\n",
        "chunk_start = re.compile('\\.W')\n",
        "med_txt_data = defaultdict(dict)\n",
        "\n",
        "def fill_dictionary(dictionary, chunk_list, marker, key_name):\n",
        "  for n in range(0,len(chunk_list)-1):\n",
        "    line = chunk_list[n+1]\n",
        "    _ , chunk = re.split(marker,line)\n",
        "    dictionary[n+1][key_name] = chunk.strip()\n",
        "\n",
        "fill_dictionary(med_txt_data, med_txt_list, chunk_start, 'text')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yQtoRnUec7GE"
      },
      "source": [
        "**Indexing**\n",
        "\n",
        "Create an index of the medline corpus for every test setting and index all the documents. This is only possible if it isn't created yet.\n",
        "\n",
        "(For more information see the [Elasticsearch documentation](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZskOyOnyc7GG",
        "colab": {}
      },
      "source": [
        "#create index, see https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create\n",
        "medline_index = \"medline-corpus\"\n",
        "stemmer_medline_index = \"stemmer-medline-corpus\"\n",
        "hunspell_medline_index = \"hunspell-medline-corpus\"\n",
        "\n",
        "es.indices.create(medline_index)\n",
        "es.indices.create(stemmer_medline_index, body=stemmer_settings)\n",
        "es.indices.create(hunspell_medline_index, body=hunspell_settings)\n",
        "#index document, see https://elasticsearch-py.readthedocs.io/en/master/#example-usage\n",
        "for ID, doc_data in medline_txt_data.items():\n",
        "  es.index(index=medline_index, id=ID, body=doc_data)\n",
        "  es.index(index=stemmer_medline_index, id=ID, body=doc_data)\n",
        "  es.index(index=hunspell_medline_index, id=ID, body=doc_data)\n",
        "\n",
        "create_response = es.cat.indices()\n",
        "print(create_response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xTX_QjdboWc4"
      },
      "source": [
        "### NPL Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z9MtEOO2oWc5"
      },
      "source": [
        "**Parsing**\n",
        "\n",
        "You can get the corpus from [this link](http://ir.dcs.gla.ac.uk/resources/test_collections/npl/).  <br>\n",
        "For detailed information about the format of the files, see the PragmaLingu [ Benchmarks](https://pragmalingu.de/docs/benchmarks/overview)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vKMMfNy0oWc6",
        "colab": {}
      },
      "source": [
        "# download and unzip data\n",
        "\n",
        "!wget http://ir.dcs.gla.ac.uk/resources/test_collections/npl/npl.tar.gz\n",
        "!tar -xf npl.tar.gz\n",
        "\n",
        "# set paths to the dowloaded data as variablesDownload and unzip data.\n",
        "\n",
        "PATH_TO_NPL_TXT = '/content/doc-text'\n",
        "\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import json\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "# get the text, query and rel files\n",
        "\n",
        "txt_entry_marker = re.compile('\\n   /\\n')\n",
        "\n",
        "def get_data(PATH_TO_FILES, marker):\n",
        "  \"\"\"\n",
        "  Reads multiple files and spilts text into entries at the entry marker.\n",
        "  The 'marker' contains the regex at which we want to split\n",
        "  Pops last element since it's empty.\n",
        "  \"\"\"\n",
        "  with open (PATH_TO_FILES,'r') as f:\n",
        "    text = f.read()\n",
        "    lines = re.split(marker,text)\n",
        "    lines.pop()\n",
        "  return lines\n",
        "\n",
        "npl_txt_list = get_data(PATH_TO_NPL_TXT, txt_entry_marker)\n",
        "\n",
        "# process the text file\n",
        "\n",
        "npl_txt_data = defaultdict(dict)\n",
        "\n",
        "for entry in npl_txt_list:\n",
        "  splitted = entry.split('\\n')\n",
        "  splitted = list(filter(None, splitted))\n",
        "  ID = splitted[0]\n",
        "  text = ' '.join(map(str, splitted[1:]))\n",
        "  npl_txt_data[ID]['text'] = text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xjgZaU7DdVef"
      },
      "source": [
        "**Indexing**\n",
        "\n",
        "Create an index of the NPL corpus for every test setting and index all the documents. This is only possible if it isn't created yet.\n",
        "\n",
        "(For more information see the [Elasticsearch documentation](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LU2H1TfhdVek",
        "colab": {}
      },
      "source": [
        "#create index, see https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create\n",
        "npl_index = \"npl-corpus\"\n",
        "stemmer_npl_index = \"stemmer-npl-corpus\"\n",
        "hunspell_npl_index = \"hunspell-npl-corpus\"\n",
        "\n",
        "es.indices.create(npl_index)\n",
        "es.indices.create(stemmer_npl_index, body=stemmer_settings)\n",
        "es.indices.create(hunspell_npl_index, body=hunspell_settings)\n",
        "#index document, see https://elasticsearch-py.readthedocs.io/en/master/#example-usage\n",
        "for ID, doc_data in npl_txt_data.items():\n",
        "  es.index(index=npl_index, id=ID, body=doc_data)\n",
        "  es.index(index=stemmer_npl_index, id=ID, body=doc_data)\n",
        "  es.index(index=hunspell_npl_index, id=ID, body=doc_data)\n",
        "\n",
        "create_response = es.cat.indices()\n",
        "print(create_response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9CQZOrdFoWcv"
      },
      "source": [
        "### Time Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Va-LJiyxoWcv"
      },
      "source": [
        "**Parsing**\n",
        "\n",
        "You can get the corpus from [this link](http://ir.dcs.gla.ac.uk/resources/test_collections/time/).  <br>\n",
        "For detailed information about the format of the files, see the PragmaLingu [ Benchmarks](https://pragmalingu.de/docs/benchmarks/overview)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w5mNWCOdoWcx",
        "colab": {}
      },
      "source": [
        "# download and unzip data\n",
        "\n",
        "!wget http://ir.dcs.gla.ac.uk/resources/test_collections/time/time.tar.gz\n",
        "!tar -xf time.tar.gz\n",
        "\n",
        "# set paths to the dowloaded data as variablesDownload and unzip data.\n",
        "\n",
        "PATH_TO_TIME_TXT = '/content/TIME.ALL'\n",
        "\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import json\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# get the text and query file\n",
        "\n",
        "txt_entry_marker = re.compile('\\*TEXT')\n",
        "\n",
        "def get_data(PATH_TO_FILES, marker):\n",
        "  \"\"\"\n",
        "  Reads multiple files and spilts text into entries at the entry marker.\n",
        "  The 'marker' contains the regex at which we want to split\n",
        "  Pops last element since it's empty.\n",
        "  \"\"\"\n",
        "  with open (PATH_TO_FILES,'r') as f:\n",
        "    text = f.read()\n",
        "    lines = re.split(marker,text)\n",
        "    lines.pop(0)\n",
        "  return lines\n",
        "\n",
        "time_txt_list = get_data(PATH_TO_TIME_TXT, txt_entry_marker)\n",
        "\n",
        "# process text file\n",
        "\n",
        "page_split = re.compile('PAGE \\d{3}')\n",
        "\n",
        "time_txt_data = defaultdict(dict)\n",
        "ID = 1\n",
        "for entry in time_txt_list:\n",
        "  splitted = re.split(page_split,entry)\n",
        "  time_txt_data[ID]['text'] = splitted[1]\n",
        "  ID += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uFJdHtsUdWbd"
      },
      "source": [
        "**Indexing**\n",
        "\n",
        "Create an index of the Time corpus for every test setting and index all the documents. This is only possible if it isn't created yet.\n",
        "\n",
        "(For more information see the [Elasticsearch documentation](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IRuA5W2WdWbe",
        "colab": {}
      },
      "source": [
        "#create index, see https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.create\n",
        "time_index = \"time-corpus\"\n",
        "stemmer_time_index = \"stemmer-time-corpus\"\n",
        "hunspell_time_index = \"hunspell-time-corpus\"\n",
        "\n",
        "es.indices.create(time_index)\n",
        "es.indices.create(stemmer_time_index, body=stemmer_settings)\n",
        "es.indices.create(hunspell_time_index, body=hunspell_settings)\n",
        "#index document, see https://elasticsearch-py.readthedocs.io/en/master/#example-usage\n",
        "for ID, doc_data in time_txt_data.items():\n",
        "  es.index(index=time_index, id=ID, body=doc_data)\n",
        "  es.index(index=stemmer_time_index, id=ID, body=doc_data)\n",
        "  es.index(index=hunspell_time_index, id=ID, body=doc_data)\n",
        "\n",
        "create_response = es.cat.indices()\n",
        "print(create_response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhXwWF1W4mIn",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MdER2AAmUwo",
        "colab_type": "text"
      },
      "source": [
        "Since the data is formatted, we can now feed it to the [Elasticsearch Ranking Evaluation API](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-rank-eval.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CemuLaUAMHKP",
        "colab_type": "text"
      },
      "source": [
        "### Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8ue08Qim8L8",
        "colab_type": "text"
      },
      "source": [
        "In this section we only evaluate the Recall scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u71ZvdbWMkIe"
      },
      "source": [
        "**Multi Match Query**\n",
        "\n",
        "Here we evaluate the data with the [\"multi_match\"](https://pragmalingu.de/docs/experiments/experiment1#standard-elasticsearch) option of elastic search:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pn_g9h7xMkIi",
        "colab": {}
      },
      "source": [
        "#use rank eval api, see https://elasticsearch-py.readthedocs.io/en/master/api.html?highlight=_rank_eval#elasticsearch.Elasticsearch.rank_eval \n",
        "#and https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-simple-query-string-query.html \n",
        "\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "cran_index = 'cranfield-corpus'\n",
        "cran_stem_index = 'stemming-cranfield-corpus'\n",
        "med_index = 'medline-corpus'\n",
        "adi_index = 'adi-corpus'\n",
        "cisi_index = 'cisi-corpus'\n",
        "cacm_index = 'cacm-corpus'\n",
        "lisa_index = 'lisa-corpus'\n",
        "time_index = 'time-corpus'\n",
        "npl_index = 'npl-corpus'\n",
        "\n",
        "#function to get normal match evaluation body \n",
        "def create_query_body_match_recall(query_dict, rel_dict, index_name):\n",
        "  \"\"\"\n",
        "  The function creates a request for every query in query_dict and rates the relevant documents with rel_dict to 1.\n",
        "  The index name has to be the same as from the documents your looking at.\n",
        "  An evaluation body for the elasticsearch ranking API is returned.\n",
        "  \"\"\"\n",
        "  eval_body = {\n",
        "      \"requests\": '',\n",
        "      \"metric\": {\n",
        "          \"recall\": {\n",
        "              \"relevant_rating_threshold\": 1,\n",
        "              \"k\": 20\n",
        "              }\n",
        "      }\n",
        "  }\n",
        "  requests = [] \n",
        "  current_request = defaultdict(lambda: defaultdict())\n",
        "  current_rel = {\"_index\": index_name, \"_id\": '', \"rating\": int}\n",
        "  for query_ID, query_txt in query_dict.items():\n",
        "    current_query = {\"query\": { \"multi_match\": { \"query\": '' , \"fields\" : [\"title\",\"text\"]}}}\n",
        "    current_query[\"query\"][\"multi_match\"][\"query\"] = query_txt['question']\n",
        "    current_request[\"id\"] = 'Query_'+str(query_ID)\n",
        "    current_request[\"request\"] = current_query.copy()\n",
        "    current_request[\"ratings\"] = [{\"_index\": index_name, \"_id\": str(el), \"rating\": 1} for el in rel_dict[query_ID]]\n",
        "    requests.append(current_request.copy())\n",
        "  eval_body[\"requests\"] = requests\n",
        "  return eval_body\n",
        "\n",
        "#Cranfield\n",
        "cran_create_match_recall = create_query_body_match_recall(cran_qry_data, cran_rel, cran_index)\n",
        "cran_eval_body_match_recall = json.dumps(cran_create_match_recall)\n",
        "cran_res_match_recall = es.rank_eval(cran_eval_body_match_recall, cran_index)\n",
        "#print(json.dumps(cran_res, indent=4, sort_keys=True))\n",
        "\n",
        "#Medline\n",
        "med_create_match_recall = create_query_body_match_recall(med_qry_data, med_rel, med_index)\n",
        "med_eval_body_match_recall = json.dumps(med_create_match_recall)\n",
        "med_res_match_recall = es.rank_eval(med_eval_body_match_recall, med_index)\n",
        "#print(json.dumps(med_res, indent=4, sort_keys=True))\n",
        "\n",
        "#ADI\n",
        "adi_create_match_recall = create_query_body_match_recall(adi_qry_data, adi_rel, adi_index)\n",
        "adi_eval_body_match_recall = json.dumps(adi_create_match_recall)\n",
        "adi_res_match_recall = es.rank_eval(adi_eval_body_match_recall, adi_index)\n",
        "#print(json.dumps(adi_create_match_recall, indent=4, sort_keys=True))\n",
        "\n",
        "#CISI\n",
        "cisi_create_match_recall = create_query_body_match_recall(cisi_qry_data, cisi_rel, cisi_index)\n",
        "cisi_eval_body_match_recall = json.dumps(cisi_create_match_recall)\n",
        "cisi_res_match_recall = es.rank_eval(cisi_eval_body_match_recall, cisi_index)\n",
        "#print(json.dumps(cisi_res, indent=4, sort_keys=True))\n",
        "\n",
        "#CACM\n",
        "cacm_create_match_recall = create_query_body_match_recall(cacm_qry_data, cacm_rel, cacm_index)\n",
        "cacm_eval_body_match_recall = json.dumps(cacm_create_match_recall)\n",
        "cacm_res_match_recall = es.rank_eval(cacm_eval_body_match_recall,cacm_index)\n",
        "#print(json.dumps(cacm_res, indent=4, sort_keys=True))\n",
        "\n",
        "#LISA\n",
        "lisa_create_match_recall = create_query_body_match_recall(lisa_qry_data, lisa_rel, lisa_index)\n",
        "lisa_eval_body_match_recall = json.dumps(lisa_create_match_recall)\n",
        "lisa_res_match_recall = es.rank_eval(lisa_eval_body_match_recall,lisa_index)\n",
        "#print(json.dumps(lisa_res, indent=4, sort_keys=True))\n",
        "\n",
        "#TIME\n",
        "time_create_match_recall = create_query_body_match_recall(time_qry_data, time_rel, time_index)\n",
        "time_eval_body_match_recall = json.dumps(time_create_match_recall)\n",
        "time_res_match_recall = es.rank_eval(time_eval_body_match_recall,time_index)\n",
        "#print(json.dumps(time_res, indent=4, sort_keys=True))\n",
        "\n",
        "#NPL\n",
        "npl_create_match_recall = create_query_body_match_recall(npl_qry_data, npl_rel, npl_index)\n",
        "npl_eval_body_match_recall = json.dumps(npl_create_match_recall)\n",
        "npl_res_match_recall = es.rank_eval(npl_eval_body_match_recall,npl_index)\n",
        "#print(json.dumps(npl_res, indent=4, sort_keys=True))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtYZw0nXnmNd",
        "colab_type": "text"
      },
      "source": [
        "**Stemmer Token Filter**\n",
        "\n",
        "Here we evaluate the data with the [\"stemmer token filter\"](https://pragmalingu.de/docs/experiments/experiment1#stemmer-token-filter) option of elastic search:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BJGIESLqMmFv",
        "colab": {}
      },
      "source": [
        "#use rank eval api, see https://elasticsearch-py.readthedocs.io/en/master/api.html?highlight=_rank_eval#elasticsearch.Elasticsearch.rank_eval \n",
        "#and https://www.elastic.co/guide/en/elasticsearch/reference/current/search-rank-eval.html#search-rank-eval\n",
        "\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "cran_index = 'stemming-cranfield-corpus'\n",
        "med_index = 'stemming-medline-corpus'\n",
        "adi_index = 'stemming-adi-corpus'\n",
        "cisi_index = 'stemming-cisi-corpus'\n",
        "cacm_index = 'stemming-cacm-corpus'\n",
        "lisa_index = 'stemming-lisa-corpus'\n",
        "time_index = 'stemming-time-corpus'\n",
        "npl_index = 'stemming-npl-corpus'\n",
        "\n",
        "#function to get normal match evaluation body \n",
        "def create_query_body_stemming_recall(query_dict, rel_dict, index_name):\n",
        "  \"\"\"\n",
        "  The function creates a request for every query in query_dict and rates the relevant documents with rel_dict to 1.\n",
        "  The index name has to be the same as from the documents your looking at.\n",
        "  An evaluation body for the elasticsearch ranking API is returned.\n",
        "  \"\"\"\n",
        "  eval_body = {\n",
        "      \"requests\":'',\n",
        "      \"metric\": {\n",
        "          \"recall\": {\n",
        "              \"k\": 20,\n",
        "              \"relevant_rating_threshold\": 1\n",
        "              }\n",
        "      }\n",
        "  }\n",
        "  requests = [] \n",
        "  current_request = defaultdict(lambda: defaultdict())\n",
        "  current_rel = {\"_index\": index_name, \"_id\": '', \"rating\": int}\n",
        "  for query_ID, query_txt in query_dict.items():\n",
        "    current_query = {\"query\": { \"multi_match\": { \"query\": '' , \"fields\" : [\"title\",\"text\"]}}}\n",
        "    current_query[\"query\"][\"multi_match\"][\"query\"] = query_txt['question']\n",
        "    current_request[\"id\"] = 'Query_'+str(query_ID)\n",
        "    current_request[\"request\"] = current_query.copy()\n",
        "    current_request[\"ratings\"] = [{\"_index\": index_name, \"_id\": str(el), \"rating\": 1} for el in rel_dict[query_ID]]\n",
        "    requests.append(current_request.copy())\n",
        "  eval_body[\"requests\"] = requests\n",
        "  return eval_body\n",
        "\n",
        "#Cranfield\n",
        "cran_create_stemming_recall = create_query_body_stemming_recall(cran_qry_data, cran_rel, cran_index)\n",
        "cran_eval_body_stemming_recall = json.dumps(cran_create_stemming_recall)\n",
        "cran_res_stemming_recall = es.rank_eval(cran_eval_body_stemming_recall, cran_index)\n",
        "#print(json.dumps(cran_res, indent=4, sort_keys=True))\n",
        "\n",
        "#Medline\n",
        "med_create_stemming_recall = create_query_body_stemming_recall(med_qry_data, med_rel, med_index)\n",
        "med_eval_body_stemming_recall = json.dumps(med_create_stemming_recall)\n",
        "med_res_stemming_recall = es.rank_eval(med_eval_body_stemming_recall, med_index)\n",
        "#print(json.dumps(med_res, indent=4, sort_keys=True))\n",
        "\n",
        "#ADI\n",
        "adi_create_stemming_recall = create_query_body_stemming_recall(adi_qry_data, adi_rel, adi_index)\n",
        "adi_eval_body_stemming_recall = json.dumps(adi_create_stemming_recall)\n",
        "adi_res_stemming_recall = es.rank_eval(adi_eval_body_stemming_recall, adi_index)\n",
        "#print(json.dumps(adi_res, indent=4, sort_keys=True))\n",
        "\n",
        "#CISI\n",
        "cisi_create_stemming_recall = create_query_body_stemming_recall(cisi_qry_data, cisi_rel, cisi_index)\n",
        "cisi_eval_body_stemming_recall = json.dumps(cisi_create_stemming_recall)\n",
        "cisi_res_stemming_recall = es.rank_eval(cisi_eval_body_stemming_recall, cisi_index)\n",
        "#print(json.dumps(cisi_res, indent=4, sort_keys=True))\n",
        "\n",
        "#CACM\n",
        "cacm_create_stemming_recall = create_query_body_stemming_recall(cacm_qry_data, cacm_rel, cacm_index)\n",
        "cacm_eval_body_stemming_recall = json.dumps(cacm_create_stemming_recall)\n",
        "cacm_res_stemming_recall = es.rank_eval(cacm_eval_body_stemming_recall,cacm_index)\n",
        "#print(json.dumps(cacm_res, indent=4, sort_keys=True))\n",
        "\n",
        "#LISA\n",
        "lisa_create_stemming_recall = create_query_body_stemming_recall(lisa_qry_data, lisa_rel, lisa_index)\n",
        "lisa_eval_body_stemming_recall = json.dumps(lisa_create_stemming_recall)\n",
        "lisa_res_stemming_recall = es.rank_eval(lisa_eval_body_stemming_recall,lisa_index)\n",
        "#print(json.dumps(lisa_res, indent=4, sort_keys=True))\n",
        "\n",
        "#TIME\n",
        "time_create_stemming_recall = create_query_body_stemming_recall(time_qry_data, time_rel, time_index)\n",
        "time_eval_body_stemming_recall = json.dumps(time_create_stemming_recall)\n",
        "time_res_stemming_recall = es.rank_eval(time_eval_body_stemming_recall,time_index)\n",
        "#print(json.dumps(time_res, indent=4, sort_keys=True))\n",
        "\n",
        "#NPL\n",
        "npl_create_stemming_recall = create_query_body_stemming_recall(npl_qry_data, npl_rel, npl_index)\n",
        "npl_eval_body_stemming_recall = json.dumps(npl_create_stemming_recall)\n",
        "npl_res_stemming_recall = es.rank_eval(npl_eval_body_stemming_recall,npl_index)\n",
        "#print(json.dumps(npl_res, indent=4, sort_keys=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keSi-TDWnxmF",
        "colab_type": "text"
      },
      "source": [
        "**Hunspell Token Filter**\n",
        "\n",
        "Here we evaluate the data with the [\"hunspell token filter\"](https://pragmalingu.de/docs/experiments/experiment1#hunspell-token-filter) option of elastic search:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vijm2d9Uwou2",
        "colab": {}
      },
      "source": [
        "#use rank eval api, see https://elasticsearch-py.readthedocs.io/en/master/api.html?highlight=_rank_eval#elasticsearch.Elasticsearch.rank_eval \n",
        "#and https://www.elastic.co/guide/en/elasticsearch/reference/current/search-rank-eval.html#search-rank-eval\n",
        "\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "cran_index = 'hunspell-cranfield-corpus'\n",
        "med_index = 'hunspell-medline-corpus'\n",
        "adi_index = 'hunspell-adi-corpus'\n",
        "cisi_index = 'hunspell-cisi-corpus'\n",
        "cacm_index = 'hunspell-cacm-corpus'\n",
        "lisa_index = 'hunspell-lisa-corpus'\n",
        "time_index = 'hunspell-time-corpus'\n",
        "npl_index = 'hunspell-npl-corpus'\n",
        "\n",
        "#function to get normal match evaluation body \n",
        "def create_query_body_hunspell_recall(query_dict, rel_dict, index_name):\n",
        "  \"\"\"\n",
        "  The function creates a request for every query in query_dict and rates the relevant documents with rel_dict to 1.\n",
        "  The index name has to be the same as from the documents your looking at.\n",
        "  An evaluation body for the elasticsearch ranking API is returned.\n",
        "  \"\"\"\n",
        "  eval_body = {\n",
        "      \"requests\":'',\n",
        "      \"metric\": {\n",
        "          \"recall\": {\n",
        "              \"k\": 20,\n",
        "              \"relevant_rating_threshold\": 1\n",
        "              }\n",
        "      }\n",
        "  }\n",
        "  requests = [] \n",
        "  current_request = defaultdict(lambda: defaultdict())\n",
        "  current_rel = {\"_index\": index_name, \"_id\": '', \"rating\": int}\n",
        "  for query_ID, query_txt in query_dict.items():\n",
        "    current_query = {\"query\": { \"multi_match\": { \"query\": '' , \"fields\" : [\"title\",\"text\"]}}}\n",
        "    current_query[\"query\"][\"multi_match\"][\"query\"] = query_txt['question']\n",
        "    current_request[\"id\"] = 'Query_'+str(query_ID)\n",
        "    current_request[\"request\"] = current_query.copy()\n",
        "    current_request[\"ratings\"] = [{\"_index\": index_name, \"_id\": str(el), \"rating\": 1} for el in rel_dict[query_ID]]\n",
        "    requests.append(current_request.copy())\n",
        "  eval_body[\"requests\"] = requests\n",
        "  return eval_body\n",
        "\n",
        "#Cranfield\n",
        "cran_create_hunspell_recall = create_query_body_hunspell_recall(cran_qry_data, cran_rel, cran_index)\n",
        "cran_eval_body_hunspell_recall = json.dumps(cran_create_hunspell_recall)\n",
        "cran_res_hunspell_recall = es.rank_eval(cran_eval_body_hunspell_recall, cran_index)\n",
        "#print(json.dumps(cran_res, indent=4, sort_keys=True))\n",
        "\n",
        "#Medline\n",
        "med_create_hunspell_recall = create_query_body_hunspell_recall(med_qry_data, med_rel, med_index)\n",
        "med_eval_body_hunspell_recall = json.dumps(med_create_hunspell_recall)\n",
        "med_res_hunspell_recall = es.rank_eval(med_eval_body_hunspell_recall, med_index)\n",
        "#print(json.dumps(med_res, indent=4, sort_keys=True))\n",
        "\n",
        "#ADI\n",
        "adi_create_hunspell_recall = create_query_body_hunspell_recall(adi_qry_data, adi_rel, adi_index)\n",
        "adi_eval_body_hunspell_recall = json.dumps(adi_create_hunspell_recall)\n",
        "adi_res_hunspell_recall = es.rank_eval(adi_eval_body_hunspell_recall, adi_index)\n",
        "#print(json.dumps(adi_res, indent=4, sort_keys=True))\n",
        "\n",
        "#CISI\n",
        "cisi_create_hunspell_recall = create_query_body_hunspell_recall(cisi_qry_data, cisi_rel, cisi_index)\n",
        "cisi_eval_body_hunspell_recall = json.dumps(cisi_create_hunspell_recall)\n",
        "cisi_res_hunspell_recall = es.rank_eval(cisi_eval_body_hunspell_recall, cisi_index)\n",
        "#print(json.dumps(cisi_res, indent=4, sort_keys=True))\n",
        "\n",
        "#CACM\n",
        "cacm_create_hunspell_recall = create_query_body_hunspell_recall(cacm_qry_data, cacm_rel, cacm_index)\n",
        "cacm_eval_body_hunspell_recall = json.dumps(cacm_create_hunspell_recall)\n",
        "cacm_res_hunspell_recall = es.rank_eval(cacm_eval_body_hunspell_recall,cacm_index)\n",
        "#print(json.dumps(cacm_res, indent=4, sort_keys=True))\n",
        "\n",
        "#LISA\n",
        "lisa_create_hunspell_recall = create_query_body_hunspell_recall(lisa_qry_data, lisa_rel, lisa_index)\n",
        "lisa_eval_body_hunspell_recall = json.dumps(lisa_create_hunspell_recall)\n",
        "lisa_res_hunspell_recall = es.rank_eval(lisa_eval_body_hunspell_recall,lisa_index)\n",
        "#print(json.dumps(lisa_res, indent=4, sort_keys=True))\n",
        "\n",
        "#TIME\n",
        "time_create_hunspell_recall = create_query_body_hunspell_recall(time_qry_data, time_rel, time_index)\n",
        "time_eval_body_hunspell_recall = json.dumps(time_create_hunspell_recall)\n",
        "time_res_hunspell_recall = es.rank_eval(time_eval_body_hunspell_recall,time_index)\n",
        "#print(json.dumps(time_res, indent=4, sort_keys=True))\n",
        "\n",
        "#NPL\n",
        "npl_create_hunspell_recall = create_query_body_hunspell_recall(npl_qry_data, npl_rel, npl_index)\n",
        "npl_eval_body_hunspell_recall = json.dumps(npl_create_hunspell_recall)\n",
        "npl_res_hunspell_recall = es.rank_eval(npl_eval_body_hunspell_recall,npl_index)\n",
        "#print(json.dumps(npl_res, indent=4, sort_keys=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJbezFbtMVp3",
        "colab_type": "text"
      },
      "source": [
        "### Precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0GNv1zbnDvt",
        "colab_type": "text"
      },
      "source": [
        "In this section we only evaluate the Precision scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8O7GlO_peURs"
      },
      "source": [
        "**Multi Match Query**\n",
        "\n",
        "Here we evaluate the data with the [\"multi_match\"](https://pragmalingu.de/docs/experiments/experiment1#standard-elasticsearch) option of elastic search:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zkCGwJ6k3ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use rank eval api, see https://elasticsearch-py.readthedocs.io/en/master/api.html?highlight=_rank_eval#elasticsearch.Elasticsearch.rank_eval \n",
        "#and https://www.elastic.co/guide/en/elasticsearch/reference/current/search-rank-eval.html#search-rank-eval\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "cran_index = 'cranfield-corpus'\n",
        "med_index = 'medline-corpus'\n",
        "adi_index = 'adi-corpus'\n",
        "cisi_index = 'cisi-corpus'\n",
        "cacm_index = 'cacm-corpus'\n",
        "lisa_index = 'lisa-corpus'\n",
        "time_index = 'time-corpus'\n",
        "npl_index = 'npl-corpus'\n",
        "\n",
        "# function to get normal match evaluation body \n",
        "\n",
        "def create_query_body_match_precision(query_dict, rel_dict, index_name):\n",
        "  \"\"\"\n",
        "  The function creates a request for every query in query_dict and rates the relevant documents with rel_dict to 1.\n",
        "  The index name has to be the same as from the documents your looking at.\n",
        "  An evaluation body for the elasticsearch ranking API is returned.\n",
        "  \"\"\"\n",
        "  eval_body = {\n",
        "      \"requests\":'',\n",
        "      \"metric\": {\n",
        "          \"precision\": {\n",
        "              \"k\": 20,\n",
        "              \"relevant_rating_threshold\": 1\n",
        "              }\n",
        "      }\n",
        "  }\n",
        "  requests = [] \n",
        "  current_request = defaultdict(lambda: defaultdict())\n",
        "  current_rel = {\"_index\": index_name, \"_id\": '', \"rating\": int}\n",
        "  for query_ID, query_txt in query_dict.items():\n",
        "    current_query = {\"query\": { \"multi_match\": { \"query\": '' , \"fields\" : [\"title\",\"text\"]}}}\n",
        "    current_query[\"query\"][\"multi_match\"][\"query\"] = query_txt['question']\n",
        "    current_request[\"id\"] = 'Query_'+str(query_ID)\n",
        "    current_request[\"request\"] = current_query.copy()\n",
        "    current_request[\"ratings\"] = [{\"_index\": index_name, \"_id\": str(el), \"rating\": 1} for el in rel_dict[query_ID]]\n",
        "    requests.append(current_request.copy())\n",
        "  eval_body[\"requests\"] = requests\n",
        "  return eval_body\n",
        "\n",
        "#Cranfield\n",
        "cran_create_match_precision = create_query_body_match_precision(cran_qry_data, cran_rel, cran_index)\n",
        "cran_eval_body_match_precision = json.dumps(cran_create_match_precision)\n",
        "cran_res_match_precision = es.rank_eval(cran_eval_body_match_precision, cran_index)\n",
        "#print(json.dumps(cran_res, indent=4, sort_keys=True))\n",
        "\n",
        "#Medline\n",
        "med_create_match_precision = create_query_body_match_precision(med_qry_data, med_rel, med_index)\n",
        "med_eval_body_match_precision = json.dumps(med_create_match_precision)\n",
        "med_res_match_precision = es.rank_eval(med_eval_body_match_precision, med_index)\n",
        "#print(json.dumps(med_res, indent=4, sort_keys=True))\n",
        "\n",
        "#Adi\n",
        "adi_create_match_precision = create_query_body_match_precision(adi_qry_data, adi_rel, adi_index)\n",
        "adi_eval_body_match_precision = json.dumps(adi_create_match_precision)\n",
        "adi_res_match_precision = es.rank_eval(adi_eval_body_match_precision, adi_index)\n",
        "#print(json.dumps(adi_res, indent=4, sort_keys=True))\n",
        "\n",
        "#CISI\n",
        "cisi_create_match_precision = create_query_body_match_precision(cisi_qry_data, cisi_rel, cisi_index)\n",
        "cisi_eval_body_match_precision = json.dumps(cisi_create_match_precision)\n",
        "cisi_res_match_precision = es.rank_eval(cisi_eval_body_match_precision, cisi_index)\n",
        "#print(json.dumps(cisi_res, indent=4, sort_keys=True))\n",
        "\n",
        "#CACM\n",
        "cacm_create_match_precision = create_query_body_match_precision(cacm_qry_data, cacm_rel, cacm_index)\n",
        "cacm_eval_body_match_precision = json.dumps(cacm_create_match_precision)\n",
        "cacm_res_match_precision = es.rank_eval(cacm_eval_body_match_precision,cacm_index)\n",
        "#print(json.dumps(cacm_res, indent=4, sort_keys=True))\n",
        "\n",
        "#LISA\n",
        "lisa_create_match_precision = create_query_body_match_precision(lisa_qry_data, lisa_rel, lisa_index)\n",
        "lisa_eval_body_match_precision = json.dumps(lisa_create_match_precision)\n",
        "lisa_res_match_precision = es.rank_eval(lisa_eval_body_match_precision,lisa_index)\n",
        "#print(json.dumps(lisa_res, indent=4, sort_keys=True))\n",
        "\n",
        "#TIME\n",
        "time_create_match_precision = create_query_body_match_precision(time_qry_data, time_rel, time_index)\n",
        "time_eval_body_match_precision = json.dumps(time_create_match_precision)\n",
        "time_res_match_precision = es.rank_eval(time_eval_body_match_precision,time_index)\n",
        "#print(json.dumps(time_res, indent=4, sort_keys=True))\n",
        "\n",
        "#NPL\n",
        "npl_create_match_precision = create_query_body_match_precision(npl_qry_data, npl_rel, npl_index)\n",
        "npl_eval_body_match_precision = json.dumps(npl_create_match_precision)\n",
        "npl_res_match_precision = es.rank_eval(npl_eval_body_match_precision,npl_index)\n",
        "#print(json.dumps(npl_res, indent=4, sort_keys=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j7eIIRaFeXNE"
      },
      "source": [
        "**Stemmer Token Filter**\n",
        "\n",
        "Here we evaluate the data with the [\"stemmer token filter\"](https://pragmalingu.de/docs/experiments/experiment1#stemmer-token-filter) option of elastic search:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q7Wrv15xsBsN",
        "colab": {}
      },
      "source": [
        "#use rank eval api, see https://elasticsearch-py.readthedocs.io/en/master/api.html?highlight=_rank_eval#elasticsearch.Elasticsearch.rank_eval \n",
        "#and https://www.elastic.co/guide/en/elasticsearch/reference/current/search-rank-eval.html#search-rank-eval\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "cran_index = 'stemming-cranfield-corpus'\n",
        "med_index = 'stemming-medline-corpus'\n",
        "adi_index = 'stemming-adi-corpus'\n",
        "cisi_index = 'stemming-cisi-corpus'\n",
        "cacm_index = 'stemming-cacm-corpus'\n",
        "lisa_index = 'stemming-lisa-corpus'\n",
        "time_index = 'stemming-time-corpus'\n",
        "npl_index = 'stemming-npl-corpus'\n",
        "\n",
        "#function to get normal match evaluation body \n",
        "\n",
        "def create_query_body_stemming_precision(query_dict, rel_dict, index_name):\n",
        "  \"\"\"\n",
        "  The function creates a request for every query in query_dict and rates the relevant documents with rel_dict to 1.\n",
        "  The index name has to be the same as from the documents your looking at.\n",
        "  An evaluation body for the elasticsearch ranking API is returned.\n",
        "  \"\"\"\n",
        "  eval_body = {\n",
        "      \"requests\":'',\n",
        "      \"metric\": {\n",
        "          \"precision\": {\n",
        "              \"k\": 20,\n",
        "              \"relevant_rating_threshold\": 1\n",
        "              }\n",
        "      }\n",
        "  }\n",
        "  requests = [] \n",
        "  current_request = defaultdict(lambda: defaultdict())\n",
        "  current_rel = {\"_index\": index_name, \"_id\": '', \"rating\": int}\n",
        "  for query_ID, query_txt in query_dict.items():\n",
        "    current_query = {\"query\": { \"multi_match\": { \"query\": '' , \"fields\" : [\"title\",\"text\"]}}}\n",
        "    current_query[\"query\"][\"multi_match\"][\"query\"] = query_txt['question']\n",
        "    current_request[\"id\"] = 'Query_'+str(query_ID)\n",
        "    current_request[\"request\"] = current_query.copy()\n",
        "    current_request[\"ratings\"] = [{\"_index\": index_name, \"_id\": str(el), \"rating\": 1} for el in rel_dict[query_ID]]\n",
        "    requests.append(current_request.copy())\n",
        "  eval_body[\"requests\"] = requests\n",
        "  return eval_body\n",
        "\n",
        "#Cranfield\n",
        "cran_create_stemming_precision = create_query_body_stemming_precision(cran_qry_data, cran_rel, cran_index)\n",
        "cran_eval_body_stemming_precision = json.dumps(cran_create_stemming_precision)\n",
        "cran_res_stemming_precision = es.rank_eval(cran_eval_body_stemming_precision, cran_index)\n",
        "#print(json.dumps(cran_res, indent=4, sort_keys=True))\n",
        "\n",
        "#Medline\n",
        "med_create_stemming_precision = create_query_body_stemming_precision(med_qry_data, med_rel, med_index)\n",
        "med_eval_body_stemming_precision = json.dumps(med_create_stemming_precision)\n",
        "med_res_stemming_precision = es.rank_eval(med_eval_body_stemming_precision, med_index)\n",
        "#print(json.dumps(med_res, indent=4, sort_keys=True))\n",
        "\n",
        "#Adi\n",
        "adi_create_stemming_precision = create_query_body_stemming_precision(adi_qry_data, adi_rel, adi_index)\n",
        "adi_eval_body_stemming_precision = json.dumps(adi_create_stemming_precision)\n",
        "adi_res_stemming_precision = es.rank_eval(adi_eval_body_stemming_precision, adi_index)\n",
        "#print(json.dumps(adi_res, indent=4, sort_keys=True))\n",
        "\n",
        "#CISI\n",
        "cisi_create_stemming_precision = create_query_body_stemming_precision(cisi_qry_data, cisi_rel, cisi_index)\n",
        "cisi_eval_body_stemming_precision = json.dumps(cisi_create_stemming_precision)\n",
        "cisi_res_stemming_precision = es.rank_eval(cisi_eval_body_stemming_precision, cisi_index)\n",
        "#print(json.dumps(cisi_res, indent=4, sort_keys=True))\n",
        "\n",
        "#CACM\n",
        "cacm_create_stemming_precision = create_query_body_stemming_precision(cacm_qry_data, cacm_rel, cacm_index)\n",
        "cacm_eval_body_stemming_precision = json.dumps(cacm_create_stemming_precision)\n",
        "cacm_res_stemming_precision = es.rank_eval(cacm_eval_body_stemming_precision,cacm_index)\n",
        "#print(json.dumps(cacm_res, indent=4, sort_keys=True))\n",
        "\n",
        "#LISA\n",
        "lisa_create_stemming_precision = create_query_body_stemming_precision(lisa_qry_data, lisa_rel, lisa_index)\n",
        "lisa_eval_body_stemming_precision = json.dumps(lisa_create_stemming_precision)\n",
        "lisa_res_stemming_precision = es.rank_eval(lisa_eval_body_stemming_precision,lisa_index)\n",
        "#print(json.dumps(lisa_res, indent=4, sort_keys=True))\n",
        "\n",
        "#TIME\n",
        "time_create_stemming_precision = create_query_body_stemming_precision(time_qry_data, time_rel, time_index)\n",
        "time_eval_body_stemming_precision = json.dumps(time_create_stemming_precision)\n",
        "time_res_stemming_precision = es.rank_eval(time_eval_body_stemming_precision,time_index)\n",
        "#print(json.dumps(time_res, indent=4, sort_keys=True))\n",
        "\n",
        "#NPL\n",
        "npl_create_stemming_precision = create_query_body_stemming_precision(npl_qry_data, npl_rel, npl_index)\n",
        "npl_eval_body_stemming_precision= json.dumps(npl_create_stemming_precision)\n",
        "npl_res_stemming_precision = es.rank_eval(npl_eval_body_stemming_precision,npl_index)\n",
        "#print(json.dumps(npl_res, indent=4, sort_keys=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5nOOQ625ea87"
      },
      "source": [
        "**Hunspell Token Filter**\n",
        "\n",
        "Here we evaluate the data with the [\"hunspell token filter\"](https://pragmalingu.de/docs/experiments/experiment1#hunspell-token-filter) option of elastic search:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "akigfsYR4-NL",
        "colab": {}
      },
      "source": [
        "#use rank eval api, see https://elasticsearch-py.readthedocs.io/en/master/api.html?highlight=_rank_eval#elasticsearch.Elasticsearch.rank_eval \n",
        "#and https://www.elastic.co/guide/en/elasticsearch/reference/current/search-rank-eval.html#search-rank-eval\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "cran_index = 'hunspell-cranfield-corpus'\n",
        "med_index = 'hunspell-medline-corpus'\n",
        "adi_index = 'hunspell-adi-corpus'\n",
        "cisi_index = 'hunspell-cisi-corpus'\n",
        "cacm_index = 'hunspell-cacm-corpus'\n",
        "lisa_index = 'hunspell-lisa-corpus'\n",
        "time_index = 'hunspell-time-corpus'\n",
        "npl_index = 'hunspell-npl-corpus'\n",
        "\n",
        "#function to get normal match evaluation body \n",
        "\n",
        "def create_query_body_hunspell_precision(query_dict, rel_dict, index_name):\n",
        "  \"\"\"\n",
        "  The function creates a request for every query in query_dict and rates the relevant documents with rel_dict to 1.\n",
        "  The index name has to be the same as from the documents your looking at.\n",
        "  An evaluation body for the elasticsearch ranking API is returned.\n",
        "  \"\"\"\n",
        "  eval_body = {\n",
        "      \"requests\":'',\n",
        "      \"metric\": {\n",
        "          \"precision\": {\n",
        "              \"k\": 20,\n",
        "              \"relevant_rating_threshold\": 1\n",
        "              }\n",
        "      }\n",
        "  }\n",
        "  requests = [] \n",
        "  current_request = defaultdict(lambda: defaultdict())\n",
        "  current_rel = {\"_index\": index_name, \"_id\": '', \"rating\": int}\n",
        "  for query_ID, query_txt in query_dict.items():\n",
        "    current_query = {\"query\": { \"multi_match\": { \"query\": '' , \"fields\" : [\"title\",\"text\"]}}}\n",
        "    current_query[\"query\"][\"multi_match\"][\"query\"] = query_txt['question']\n",
        "    current_request[\"id\"] = 'Query_'+str(query_ID)\n",
        "    current_request[\"request\"] = current_query.copy()\n",
        "    current_request[\"ratings\"] = [{\"_index\": index_name, \"_id\": str(el), \"rating\": 1} for el in rel_dict[query_ID]]\n",
        "    requests.append(current_request.copy())\n",
        "  eval_body[\"requests\"] = requests\n",
        "  return eval_body\n",
        "\n",
        "#Cranfield\n",
        "cran_create_hunspell_precision = create_query_body_hunspell_precision(cran_qry_data, cran_rel, cran_index)\n",
        "cran_eval_body_hunspell_precision = json.dumps(cran_create_hunspell_precision)\n",
        "cran_res_hunspell_precision = es.rank_eval(cran_eval_body_hunspell_precision, cran_index)\n",
        "#print(json.dumps(cran_res, indent=4, sort_keys=True))\n",
        "\n",
        "#Medline\n",
        "med_create_hunspell_precision = create_query_body_hunspell_precision(med_qry_data, med_rel, med_index)\n",
        "med_eval_body_hunspell_precision = json.dumps(med_create_hunspell_precision)\n",
        "med_res_hunspell_precision = es.rank_eval(med_eval_body_hunspell_precision, med_index)\n",
        "#print(json.dumps(med_res, indent=4, sort_keys=True))\n",
        "\n",
        "#Adi\n",
        "adi_create_hunspell_precision = create_query_body_hunspell_precision(adi_qry_data, adi_rel, adi_index)\n",
        "adi_eval_body_hunspell_precision = json.dumps(adi_create_hunspell_precision)\n",
        "adi_res_hunspell_precision = es.rank_eval(adi_eval_body_hunspell_precision, adi_index)\n",
        "#print(json.dumps(adi_res, indent=4, sort_keys=True))\n",
        "\n",
        "#CISI\n",
        "cisi_create_hunspell_precision = create_query_body_hunspell_precision(cisi_qry_data, cisi_rel, cisi_index)\n",
        "cisi_eval_body_hunspell_precision = json.dumps(cisi_create_hunspell_precision)\n",
        "cisi_res_hunspell_precision = es.rank_eval(cisi_eval_body_hunspell_precision, cisi_index)\n",
        "#print(json.dumps(cisi_res, indent=4, sort_keys=True))\n",
        "\n",
        "#CACM\n",
        "cacm_create_hunspell_precision = create_query_body_hunspell_precision(cacm_qry_data, cacm_rel, cacm_index)\n",
        "cacm_eval_body_hunspell_precision = json.dumps(cacm_create_hunspell_precision)\n",
        "cacm_res_hunspell_precision = es.rank_eval(cacm_eval_body_hunspell_precision,cacm_index)\n",
        "#print(json.dumps(cacm_res, indent=4, sort_keys=True))\n",
        "\n",
        "#LISA\n",
        "lisa_create_hunspell_precision = create_query_body_hunspell_precision(lisa_qry_data, lisa_rel, lisa_index)\n",
        "lisa_eval_body_hunspell_precision = json.dumps(lisa_create_hunspell_precision)\n",
        "lisa_res_hunspell_precision = es.rank_eval(lisa_eval_body_hunspell_precision,lisa_index)\n",
        "#print(json.dumps(lisa_res, indent=4, sort_keys=True))\n",
        "\n",
        "#TIME\n",
        "time_create_hunspell_precision = create_query_body_hunspell_precision(time_qry_data, time_rel, time_index)\n",
        "time_eval_body_hunspell_precision = json.dumps(time_create_hunspell_precision)\n",
        "time_res_hunspell_precision = es.rank_eval(time_eval_body_hunspell_precision,time_index)\n",
        "#print(json.dumps(time_res, indent=4, sort_keys=True))\n",
        "\n",
        "#NPL\n",
        "npl_create_hunspell_precision = create_query_body_hunspell_precision(npl_qry_data, npl_rel, npl_index)\n",
        "npl_eval_body_hunspell_precision= json.dumps(npl_create_hunspell_precision)\n",
        "npl_res_hunspell_precision = es.rank_eval(npl_eval_body_hunspell_precision,npl_index)\n",
        "#print(json.dumps(npl_res, indent=4, sort_keys=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4xAOamijd4r",
        "colab_type": "text"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh0oRxrzny0d",
        "colab_type": "text"
      },
      "source": [
        "The last step is to visualize the data so we can analyze the differences:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltLnp1BTWUoY",
        "colab_type": "text"
      },
      "source": [
        "### Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tfiqvVDvWX6m",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "match_metrics_recall = []\n",
        "match_metrics_recall.append(round(cran_res_match_recall['metric_score'], 3))\n",
        "match_metrics_recall.append(round(cisi_res_match_recall['metric_score'], 3))\n",
        "match_metrics_recall.append(round(adi_res_match_recall['metric_score'], 3))\n",
        "match_metrics_recall.append(round(med_res_match_recall['metric_score'], 3))\n",
        "match_metrics_recall.append(round(cacm_res_match_recall['metric_score'], 3))\n",
        "match_metrics_recall.append(round(lisa_res_match_recall['metric_score'], 3))\n",
        "match_metrics_recall.append(round(time_res_match_recall['metric_score'], 3))\n",
        "match_metrics_recall.append(round(npl_res_match_recall['metric_score'], 3))\n",
        "\n",
        "stemming_metrics_recall = []\n",
        "stemming_metrics_recall.append(round(cran_res_stemming_recall['metric_score'], 3))\n",
        "stemming_metrics_recall.append(round(cisi_res_stemming_recall['metric_score'], 3))\n",
        "stemming_metrics_recall.append(round(adi_res_stemming_recall['metric_score'], 3))\n",
        "stemming_metrics_recall.append(round(med_res_stemming_recall['metric_score'], 3))\n",
        "stemming_metrics_recall.append(round(cacm_res_stemming_recall['metric_score'], 3))\n",
        "stemming_metrics_recall.append(round(lisa_res_stemming_recall['metric_score'], 3))\n",
        "stemming_metrics_recall.append(round(time_res_stemming_recall['metric_score'], 3))\n",
        "stemming_metrics_recall.append(round(npl_res_stemming_recall['metric_score'], 3))\n",
        "\n",
        "hunspell_metrics_recall = []\n",
        "hunspell_metrics_recall.append(round(cran_res_hunspell_recall['metric_score'], 3))\n",
        "hunspell_metrics_recall.append(round(cisi_res_hunspell_recall['metric_score'], 3))\n",
        "hunspell_metrics_recall.append(round(adi_res_hunspell_recall['metric_score'], 3))\n",
        "hunspell_metrics_recall.append(round(med_res_hunspell_recall['metric_score'], 3))\n",
        "hunspell_metrics_recall.append(round(cacm_res_hunspell_recall['metric_score'], 3))\n",
        "hunspell_metrics_recall.append(round(lisa_res_hunspell_recall['metric_score'], 3))\n",
        "hunspell_metrics_recall.append(round(time_res_hunspell_recall['metric_score'], 3))\n",
        "hunspell_metrics_recall.append(round(npl_res_hunspell_recall['metric_score'], 3))\n",
        "\n",
        "labels = ['cranfield', 'CISI', 'ADI', 'medline', 'CACM','LISA','Time','NPL']\n",
        "\n",
        "x = np.arange(len(labels))*1.8  # the label locations\n",
        "\n",
        "width = 0.5  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width, match_metrics_recall , width, label='With multi match')\n",
        "rects2 = ax.bar(x, stemming_metrics_recall, width, label='With stemming')\n",
        "rects3 = ax.bar(x + width, hunspell_metrics_recall, width, label='With hunspell')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('metric scores')\n",
        "ax.set_title('Recall scores by corpus')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "autolabel(rects3)\n",
        "\n",
        "fig.tight_layout()\n",
        "fig.set_figwidth(16)\n",
        "fig.set_figheight(8)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZuaqJuC8T_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "match_metrics_recall.insert(0, 'standard search') \n",
        "stemming_metrics_recall.insert(0, 'stemming search') \n",
        "hunspell_metrics_recall.insert(0, 'hunspell search')\n",
        "\n",
        "l = [match_metrics_recall, stemming_metrics_recall, hunspell_metrics_recall]\n",
        "table = tabulate(l, headers=['cranfield', 'CISI', 'ADI', 'medline', 'CACM','LISA','Time','NPL'], tablefmt='orgtbl')\n",
        "\n",
        "print(table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57olkUd6WQ3C",
        "colab_type": "text"
      },
      "source": [
        "### Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvjJ8xRilGKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "match_metrics_precision = []\n",
        "match_metrics_precision.append(round(cran_res_match_precision['metric_score'], 3))\n",
        "match_metrics_precision.append(round(cisi_res_match_precision['metric_score'], 3))\n",
        "match_metrics_precision.append(round(adi_res_match_precision['metric_score'], 3))\n",
        "match_metrics_precision.append(round(med_res_match_precision['metric_score'], 3))\n",
        "match_metrics_precision.append(round(cacm_res_match_precision['metric_score'], 3))\n",
        "match_metrics_precision.append(round(lisa_res_match_precision['metric_score'], 3))\n",
        "match_metrics_precision.append(round(time_res_match_precision['metric_score'], 3))\n",
        "match_metrics_precision.append(round(npl_res_match_precision['metric_score'], 3))\n",
        "\n",
        "stemming_metrics_precision = []\n",
        "stemming_metrics_precision.append(round(cran_res_stemming_precision['metric_score'], 3))\n",
        "stemming_metrics_precision.append(round(cisi_res_stemming_precision['metric_score'], 3))\n",
        "stemming_metrics_precision.append(round(adi_res_stemming_precision['metric_score'], 3))\n",
        "stemming_metrics_precision.append(round(med_res_stemming_precision['metric_score'], 3))\n",
        "stemming_metrics_precision.append(round(cacm_res_stemming_precision['metric_score'], 3))\n",
        "stemming_metrics_precision.append(round(lisa_res_stemming_precision['metric_score'], 3))\n",
        "stemming_metrics_precision.append(round(time_res_stemming_precision['metric_score'], 3))\n",
        "stemming_metrics_precision.append(round(npl_res_stemming_precision['metric_score'], 3))\n",
        "\n",
        "hunspell_metrics_precision = []\n",
        "hunspell_metrics_precision.append(round(cran_res_hunspell_precision['metric_score'], 3))\n",
        "hunspell_metrics_precision.append(round(cisi_res_hunspell_precision['metric_score'], 3))\n",
        "hunspell_metrics_precision.append(round(adi_res_hunspell_precision['metric_score'], 3))\n",
        "hunspell_metrics_precision.append(round(med_res_hunspell_precision['metric_score'], 3))\n",
        "hunspell_metrics_precision.append(round(cacm_res_hunspell_precision['metric_score'], 3))\n",
        "hunspell_metrics_precision.append(round(lisa_res_hunspell_precision['metric_score'], 3))\n",
        "hunspell_metrics_precision.append(round(time_res_hunspell_precision['metric_score'], 3))\n",
        "hunspell_metrics_precision.append(round(npl_res_hunspell_precision['metric_score'], 3))\n",
        "\n",
        "labels = ['cranfield', 'CISI', 'ADI', 'medline', 'CACM','LISA','Time','NPL']\n",
        "\n",
        "x = np.arange(len(labels))*1.8  # the label locations\n",
        "\n",
        "width = 0.5  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width, match_metrics_precision , width, label='With multi match')\n",
        "rects2 = ax.bar(x, stemming_metrics_precision, width, label='With stemming')\n",
        "rects3 = ax.bar(x + width, hunspell_metrics_precision, width, label='With hunspell')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('metric scores')\n",
        "ax.set_title('Scores by corpus')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "autolabel(rects3)\n",
        "\n",
        "fig.tight_layout()\n",
        "fig.set_figwidth(16)\n",
        "fig.set_figheight(8)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZfXXKUJe_XK2",
        "colab": {}
      },
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "match_metrics_precision.insert(0, 'standard search') \n",
        "stemming_metrics_precision.insert(0, 'stemming search') \n",
        "\n",
        "l = [match_metrics_precision, stemming_metrics_precision]\n",
        "table = tabulate(l, headers=['cranfield', 'CISI', 'ADI', 'medline', 'CACM','LISA','Time','NPL'], tablefmt='orgtbl')\n",
        "\n",
        "print(table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm1Aej_-T9e0",
        "colab_type": "text"
      },
      "source": [
        "### F-Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QA8CpbbRQtIH",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def f_score(recall,precision):\n",
        "  fscore = 2*((recall*precision)/(recall+precision))\n",
        "  return fscore\n",
        "\n",
        "match_metrics_fscore = []\n",
        "match_metrics_fscore.append(round(f_score(cran_res_match_recall['metric_score'], cran_res_match_precision['metric_score']),3))\n",
        "match_metrics_fscore.append(round(f_score(cisi_res_match_recall['metric_score'], cisi_res_match_precision['metric_score']),3))\n",
        "match_metrics_fscore.append(round(f_score(adi_res_match_recall['metric_score'], adi_res_match_precision['metric_score']),3))\n",
        "match_metrics_fscore.append(round(f_score(med_res_match_recall['metric_score'], med_res_match_precision['metric_score']),3))\n",
        "match_metrics_fscore.append(round(f_score(cacm_res_match_recall['metric_score'], cacm_res_match_precision['metric_score']),3))\n",
        "match_metrics_fscore.append(round(f_score(lisa_res_match_recall['metric_score'], lisa_res_match_precision['metric_score']),3))\n",
        "match_metrics_fscore.append(round(f_score(time_res_match_recall['metric_score'], time_res_match_precision['metric_score']),3))\n",
        "match_metrics_fscore.append(round(f_score(npl_res_match_recall['metric_score'], npl_res_match_precision['metric_score']),3))\n",
        "\n",
        "stemming_metrics_fscore = []\n",
        "stemming_metrics_fscore.append(round(f_score(cran_res_stemming_recall['metric_score'], cran_res_stemming_precision['metric_score']),3))\n",
        "stemming_metrics_fscore.append(round(f_score(cisi_res_stemming_recall['metric_score'], cisi_res_stemming_precision['metric_score']),3))\n",
        "stemming_metrics_fscore.append(round(f_score(adi_res_stemming_recall['metric_score'], adi_res_stemming_precision['metric_score']),3))\n",
        "stemming_metrics_fscore.append(round(f_score(med_res_stemming_recall['metric_score'], med_res_stemming_precision['metric_score']),3))\n",
        "stemming_metrics_fscore.append(round(f_score(cacm_res_stemming_recall['metric_score'], cacm_res_stemming_precision['metric_score']),3))\n",
        "stemming_metrics_fscore.append(round(f_score(lisa_res_stemming_recall['metric_score'], lisa_res_stemming_precision['metric_score']),3))\n",
        "stemming_metrics_fscore.append(round(f_score(time_res_stemming_recall['metric_score'], time_res_stemming_precision['metric_score']),3))\n",
        "stemming_metrics_fscore.append(round(f_score(npl_res_stemming_recall['metric_score'], npl_res_stemming_precision['metric_score']),3))\n",
        "\n",
        "hunspell_metrics_fscore = []\n",
        "hunspell_metrics_fscore.append(round(f_score(cran_res_hunspell_recall['metric_score'], cran_res_hunspell_precision['metric_score']),3))\n",
        "hunspell_metrics_fscore.append(round(f_score(cisi_res_hunspell_recall['metric_score'], cisi_res_hunspell_precision['metric_score']),3))\n",
        "hunspell_metrics_fscore.append(round(f_score(adi_res_hunspell_recall['metric_score'], adi_res_hunspell_precision['metric_score']),3))\n",
        "hunspell_metrics_fscore.append(round(f_score(med_res_hunspell_recall['metric_score'], med_res_hunspell_precision['metric_score']),3))\n",
        "hunspell_metrics_fscore.append(round(f_score(cacm_res_hunspell_recall['metric_score'], cacm_res_hunspell_precision['metric_score']),3))\n",
        "hunspell_metrics_fscore.append(round(f_score(lisa_res_hunspell_recall['metric_score'], lisa_res_hunspell_precision['metric_score']),3))\n",
        "hunspell_metrics_fscore.append(round(f_score(time_res_hunspell_recall['metric_score'], time_res_hunspell_precision['metric_score']),3))\n",
        "hunspell_metrics_fscore.append(round(f_score(npl_res_hunspell_recall['metric_score'], npl_res_hunspell_precision['metric_score']),3))\n",
        "\n",
        "labels = ['cranfield', 'CISI', 'ADI', 'medline', 'CACM','LISA','Time','NPL']\n",
        "\n",
        "x = np.arange(len(labels))*1.8  # the label locations\n",
        "\n",
        "width = 0.5  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width, match_metrics_fscore , width, label='With multi match')\n",
        "rects2 = ax.bar(x, stemming_metrics_fscore, width, label='With stemming')\n",
        "rects3 = ax.bar(x + width, hunspell_metrics_fscore, width, label='With hunspell')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('metric scores')\n",
        "ax.set_title('Scores by corpus')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "autolabel(rects3)\n",
        "\n",
        "fig.tight_layout()\n",
        "fig.set_figwidth(16)\n",
        "fig.set_figheight(8)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R6Tk6Vt8Ah5_",
        "colab": {}
      },
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "match_metrics_fscore.insert(0, 'standard search') \n",
        "stemming_metrics_fscore.insert(0, 'stemming search') \n",
        "#hunspell_metrics_fscore.insert(0, 'stemming hunspell search')\n",
        "\n",
        "l = [match_metrics_fscore, stemming_metrics_fscore]\n",
        "table = tabulate(l, headers=['cranfield', 'CISI', 'ADI', 'medline', 'CACM','LISA','Time','NPL'], tablefmt='orgtbl')\n",
        "\n",
        "print(table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikgcrccon7a1",
        "colab_type": "text"
      },
      "source": [
        "Read more on this experiment on our [website](https://pragmalingu.de/docs/experiments/experiment1)."
      ]
    }
  ]
}